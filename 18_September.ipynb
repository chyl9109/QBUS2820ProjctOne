{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from ExtraCode import getResultTable\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from QBUS2820 import forward\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from QBUS2820 import pcrCV\n",
    "from QBUS2820 import plsCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_del&bin20.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "method = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr=pcrCV(final_train, y_train)\n",
    "predpcr = pcr.predict(final_test)\n",
    "method.append('PCR')\n",
    "pred.append(np.exp(predpcr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor = np.arange(1,101)\n",
    "optimalk = 0\n",
    "low = np.inf\n",
    "for i in neighbor:\n",
    "    knn1 = KNeighborsRegressor(n_neighbors=i) \n",
    "    predictions = knn1.fit(final_train, y_train)\n",
    "    predictionsfin = predictions.predict(final_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, np.exp(predictionsfin)))\n",
    "    if rmse < low:\n",
    "        low = rmse\n",
    "        optimalk = i\n",
    "print('Optimal k is {}'.format(optimalk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn1 = KNeighborsRegressor(n_neighbors=optimalk) \n",
    "predictions = knn1.fit(final_train, y_train)\n",
    "predknn = knn1.predict(final_test)\n",
    "method.append('KNN with optimal {}'.format(optimalk))\n",
    "pred.append(np.exp(predknn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(final_train, y_train)\n",
    "predforward = fwd.predict(final_test)\n",
    "method.append('Forward')\n",
    "pred.append(np.exp(predforward))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(final_train,y_train)\n",
    "predFinalBoost = GBoost.predict(final_test)\n",
    "method.append('GBoost')\n",
    "pred.append(np.exp(predFinalBoost))\n",
    "\n",
    "regr = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "method.append('AdaBoost')\n",
    "pred.append(np.exp(adapred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "testFinaldmat = xgb.DMatrix(final_test)\n",
    "xgpred = final_gb.predict(testFinaldmat)\n",
    "method.append('XGBoost')\n",
    "pred.append(np.exp(xgpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = (np.exp(xgpred)+np.exp(adapred)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred2)\n",
    "method.append('XGBoost, ada, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = (np.exp(xgpred)+np.exp(predFinalBoost))/2\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(adapred))/2\n",
    "pred.append(pred3)\n",
    "pred.append(pred5)\n",
    "method.append('xg GB')\n",
    "method.append('xg adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(final_train,y_train)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(final_test)\n",
    "pred.append(np.exp(predFinalExtRandomForestlad))\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred5 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred5)\n",
    "method.append('XGBoost, random tree, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred6 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad))/2\n",
    "pred.append(pred6)\n",
    "method.append('xg Random tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred10 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred10)\n",
    "method.append('XGBoost, GBoost Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(final_train, np.ravel(y_train)) \n",
    "pred_L = lasso.predict(final_test)\n",
    "method.append('LASSO')\n",
    "pred.append(np.exp(pred_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(final_train, y_train)\n",
    "y_pred_rg = (rg.predict(final_test))\n",
    "y_pred_rg\n",
    "\n",
    "pred.append(np.exp(y_pred_rg))\n",
    "method.append('Ridge alpha 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred11 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4\n",
    "pred.append(pred11)\n",
    "method.append('XGBoost, GBoost Random Forest Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred_L))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regr = ElasticNet(random_state=0, alpha = 1)\n",
    "    \n",
    "regr.fit(final_train, y_train)    \n",
    "pred13 = regr.predict(final_test)\n",
    "pred.append(np.exp(pred13))\n",
    "method.append('ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred13))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred13 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg))/3\n",
    "pred.append(pred13)\n",
    "method.append('XGBoost, GBoost Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred14 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward))/4\n",
    "pred.append(pred14)\n",
    "method.append('XGBoost, GBoost Ridge Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(pred_L))/5\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+ np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost, RandomTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred15 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = ((0.4*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward 40 40 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred17 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred17)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred18 = ((0.35*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.15*np.exp(y_pred_rg))+(0.15*np.exp(predforward)))\n",
    "pred.append(pred18)\n",
    "method.append('XGBoost, GBoost Ridge Forward 35 35 15 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred19 = ((0.25*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred19)\n",
    "method.append('XGBoost, GBoost Ridge Forward 25 35 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred20 = ((0.2*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred20)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 40 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred21 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred21)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 20 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred22 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred22)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 30 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred23 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred23)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.3*np.exp(xgpred))+(0.5*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 50 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.4*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 20 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred25 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred25)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 30 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred26 = ((0.26*np.exp(xgpred))+(0.27*np.exp(predFinalBoost))+(0.27*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred26)\n",
    "method.append('XGBoost, GBoost Ridge Forward 26 27 27 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred27 = ((0.23*np.exp(xgpred))+(0.24*np.exp(predFinalBoost))+(0.24*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred27)\n",
    "method.append('XGBoost, GBoost Ridge Forward 23 24 24 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>18186.830</td>\n",
       "      <td>994.962</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.012</td>\n",
       "      <td>13563.566</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>17402.679</td>\n",
       "      <td>910.398</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.010</td>\n",
       "      <td>13102.537</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>20179.764</td>\n",
       "      <td>2922.195</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13653.008</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>26758.993</td>\n",
       "      <td>3946.798</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.027</td>\n",
       "      <td>17910.399</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>21028.986</td>\n",
       "      <td>2903.143</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.016</td>\n",
       "      <td>14126.288</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>21084.880</td>\n",
       "      <td>3507.691</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13723.013</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>19858.438</td>\n",
       "      <td>3021.117</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13182.916</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>22618.701</td>\n",
       "      <td>3626.093</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.022</td>\n",
       "      <td>14767.022</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>26902.537</td>\n",
       "      <td>3813.769</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.026</td>\n",
       "      <td>18044.031</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>21122.984</td>\n",
       "      <td>3458.843</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13801.516</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>22681.380</td>\n",
       "      <td>3554.886</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.021</td>\n",
       "      <td>14886.174</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>21122.984</td>\n",
       "      <td>3458.843</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13801.516</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>27578.086</td>\n",
       "      <td>1826.395</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.025</td>\n",
       "      <td>18990.719</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>15878.751</td>\n",
       "      <td>874.747</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.009</td>\n",
       "      <td>11868.352</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>18778.339</td>\n",
       "      <td>2420.882</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12795.485</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>20561.951</td>\n",
       "      <td>2711.560</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.014</td>\n",
       "      <td>13797.288</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>26247.532</td>\n",
       "      <td>1871.496</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.022</td>\n",
       "      <td>17774.318</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>20476.312</td>\n",
       "      <td>2814.708</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.015</td>\n",
       "      <td>13641.802</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>17450.152</td>\n",
       "      <td>1836.259</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12242.700</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>16142.723</td>\n",
       "      <td>1039.642</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11774.490</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>17099.909</td>\n",
       "      <td>1491.135</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.006</td>\n",
       "      <td>12116.436</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Lasso</th>\n",
       "      <td>16678.990</td>\n",
       "      <td>1084.365</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12139.069</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost, RandomTree</th>\n",
       "      <td>21122.984</td>\n",
       "      <td>3458.843</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13801.516</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 20 20</th>\n",
       "      <td>16645.276</td>\n",
       "      <td>1310.296</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11961.580</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 40 40 10 10</th>\n",
       "      <td>18039.820</td>\n",
       "      <td>2077.057</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12496.885</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>15787.588</td>\n",
       "      <td>869.379</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11668.531</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 35 35 15 15</th>\n",
       "      <td>17282.392</td>\n",
       "      <td>1663.221</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12206.856</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 25 35 20 20</th>\n",
       "      <td>16634.163</td>\n",
       "      <td>1309.661</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11961.656</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 40 20 20</th>\n",
       "      <td>16641.299</td>\n",
       "      <td>1308.693</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11970.733</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 20 30</th>\n",
       "      <td>16090.119</td>\n",
       "      <td>997.281</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11777.482</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 30 20</th>\n",
       "      <td>16202.655</td>\n",
       "      <td>1090.465</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11793.361</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>15787.588</td>\n",
       "      <td>869.379</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11668.531</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 50 10 10</th>\n",
       "      <td>18006.288</td>\n",
       "      <td>2073.108</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12484.500</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 20 40</th>\n",
       "      <td>15753.014</td>\n",
       "      <td>834.422</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11673.102</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 30 10</th>\n",
       "      <td>16836.245</td>\n",
       "      <td>1460.581</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12013.052</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 26 27 27 20</th>\n",
       "      <td>16326.231</td>\n",
       "      <td>1150.595</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11835.077</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 23 24 24 30</th>\n",
       "      <td>15967.212</td>\n",
       "      <td>915.876</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11793.249</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Test RMSE        SE  Jack R2  \\\n",
       "PCR                                        18186.830   994.962    0.932   \n",
       "Forward                                    17402.679   910.398    0.938   \n",
       "GBoost                                     20179.764  2922.195    0.917   \n",
       "AdaBoost                                   26758.993  3946.798    0.854   \n",
       "XGBoost                                    21028.986  2903.143    0.910   \n",
       "XGBoost, ada, GB                           21084.880  3507.691    0.909   \n",
       "xg GB                                      19858.438  3021.117    0.919   \n",
       "xg adaboost                                22618.701  3626.093    0.895   \n",
       "Random Forest                              26902.537  3813.769    0.852   \n",
       "XGBoost, random tree, GB                   21122.984  3458.843    0.909   \n",
       "xg Random tree                             22681.380  3554.886    0.895   \n",
       "XGBoost, GBoost Random Forest              21122.984  3458.843    0.909   \n",
       "LASSO                                      27578.086  1826.395    0.845   \n",
       "Ridge alpha 10                             15878.751   874.747    0.948   \n",
       "XGBoost, GBoost Random Forest Ridge        18778.339  2420.882    0.928   \n",
       "XGBoost, GBoost Random Forest LASSO        20561.951  2711.560    0.914   \n",
       "ENET                                       26247.532  1871.496    0.859   \n",
       "XGBoost, GBoost Random Forest ENET         20476.312  2814.708    0.914   \n",
       "XGBoost, GBoost Ridge                      17450.152  1836.259    0.938   \n",
       "XGBoost, GBoost Ridge Forward              16142.723  1039.642    0.947   \n",
       "XGBoost, GBoost Ridge Forward Tree         17099.909  1491.135    0.940   \n",
       "XGBoost, GBoost Ridge Forward Lasso        16678.990  1084.365    0.943   \n",
       "XGBoost, GBoost, RandomTree                21122.984  3458.843    0.909   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  16645.276  1310.296    0.943   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  18039.820  2077.057    0.933   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  15787.588   869.379    0.949   \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15  17282.392  1663.221    0.939   \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20  16634.163  1309.661    0.943   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  16641.299  1308.693    0.943   \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30  16090.119   997.281    0.947   \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20  16202.655  1090.465    0.946   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  15787.588   869.379    0.949   \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  18006.288  2073.108    0.934   \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40  15753.014   834.422    0.949   \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  16836.245  1460.581    0.942   \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  16326.231  1150.595    0.946   \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30  15967.212   915.876    0.948   \n",
       "\n",
       "                                              SE        MAE  R-square  \n",
       "PCR                                        0.012  13563.566     0.932  \n",
       "Forward                                    0.010  13102.537     0.938  \n",
       "GBoost                                     0.016  13653.008     0.917  \n",
       "AdaBoost                                   0.027  17910.399     0.854  \n",
       "XGBoost                                    0.016  14126.288     0.910  \n",
       "XGBoost, ada, GB                           0.020  13723.013     0.909  \n",
       "xg GB                                      0.016  13182.916     0.919  \n",
       "xg adaboost                                0.022  14767.022     0.895  \n",
       "Random Forest                              0.026  18044.031     0.852  \n",
       "XGBoost, random tree, GB                   0.020  13801.516     0.909  \n",
       "xg Random tree                             0.021  14886.174     0.895  \n",
       "XGBoost, GBoost Random Forest              0.020  13801.516     0.909  \n",
       "LASSO                                      0.025  18990.719     0.845  \n",
       "Ridge alpha 10                             0.009  11868.352     0.948  \n",
       "XGBoost, GBoost Random Forest Ridge        0.011  12795.485     0.928  \n",
       "XGBoost, GBoost Random Forest LASSO        0.014  13797.288     0.914  \n",
       "ENET                                       0.022  17774.318     0.859  \n",
       "XGBoost, GBoost Random Forest ENET         0.015  13641.802     0.914  \n",
       "XGBoost, GBoost Ridge                      0.008  12242.700     0.938  \n",
       "XGBoost, GBoost Ridge Forward              0.006  11774.490     0.947  \n",
       "XGBoost, GBoost Ridge Forward Tree         0.006  12116.436     0.940  \n",
       "XGBoost, GBoost Ridge Forward Lasso        0.007  12139.069     0.943  \n",
       "XGBoost, GBoost, RandomTree                0.020  13801.516     0.909  \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  0.006  11961.580     0.943  \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  0.009  12496.885     0.933  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.007  11668.531     0.949  \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15  0.007  12206.856     0.939  \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20  0.006  11961.656     0.943  \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  0.006  11970.733     0.943  \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30  0.007  11777.482     0.947  \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20  0.006  11793.361     0.946  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.007  11668.531     0.949  \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  0.009  12484.500     0.934  \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40  0.008  11673.102     0.949  \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  0.007  12013.052     0.942  \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  0.006  11835.077     0.946  \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30  0.007  11793.249     0.948  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResultTable(rows, predictions):\n",
    "    columns=['Test RMSE', 'SE', 'Jack R2', 'SE', 'MAE', 'R-square']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        results.iloc[row,0], results.iloc[row,1] = rmse_jack(y_test, pred)\n",
    "        results.iloc[row,2], results.iloc[row,3] = (r2_jack(y_test, pred))\n",
    "        results.iloc[row,4] = mean_absolute_error(y_test, pred)\n",
    "        results.iloc[row,5] = r2_score(y_test,pred)\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_del_332.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test_del_332.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = ((0.15*np.exp(prediction))+(0.35*np.exp(predFinalBoost))+(0.15*np.exp(y_pred_rg) + (0.35*np.exp(predforward))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction.to_csv(\"Day18_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>90807.229520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>163753.280426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>134565.541332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>186791.822738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>151033.594125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>320050.960626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>131325.897713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>281905.802572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>118401.016685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>133941.742398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>139358.150508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>136083.660876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>181936.378538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>247113.382169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>139061.866510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>112086.719791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>233206.324453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>77575.234909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>177693.331523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>137082.117841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>286748.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>184667.341119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>139395.099870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>125150.510160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>132980.991388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>137952.406318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>170910.648257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>119813.236879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>211470.075016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>286988.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>233126.529644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>262764.348682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>149900.677518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>193801.210804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>124384.269580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>287624.879094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>237557.573530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>167721.702497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>143969.217727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>152428.844470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>118969.430321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>91049.863032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>126232.935861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>162015.411613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>200053.285967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>124284.098579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>279474.587195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>191975.460336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>214481.349024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>219464.719746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>156464.201680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>156505.654816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>440538.447326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>54727.813283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>168316.355027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>166320.339832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>144306.797318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>88349.143390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>194643.922521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>212470.184375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   90807.229520\n",
       "1        2  163753.280426\n",
       "2        3  134565.541332\n",
       "3        4  186791.822738\n",
       "4        5  151033.594125\n",
       "5        6  320050.960626\n",
       "6        7  131325.897713\n",
       "7        8  281905.802572\n",
       "8        9  118401.016685\n",
       "9       10  133941.742398\n",
       "10      11  139358.150508\n",
       "11      12  136083.660876\n",
       "12      13  181936.378538\n",
       "13      14  247113.382169\n",
       "14      15  139061.866510\n",
       "15      16  112086.719791\n",
       "16      17  233206.324453\n",
       "17      18   77575.234909\n",
       "18      19  177693.331523\n",
       "19      20  137082.117841\n",
       "20      21  286748.006513\n",
       "21      22  184667.341119\n",
       "22      23  139395.099870\n",
       "23      24  125150.510160\n",
       "24      25  132980.991388\n",
       "25      26  137952.406318\n",
       "26      27  170910.648257\n",
       "27      28  119813.236879\n",
       "28      29  211470.075016\n",
       "29      30  286988.230100\n",
       "...    ...            ...\n",
       "1578  1579  233126.529644\n",
       "1579  1580  262764.348682\n",
       "1580  1581  149900.677518\n",
       "1581  1582  193801.210804\n",
       "1582  1583  124384.269580\n",
       "1583  1584  287624.879094\n",
       "1584  1585  237557.573530\n",
       "1585  1586  167721.702497\n",
       "1586  1587  143969.217727\n",
       "1587  1588  152428.844470\n",
       "1588  1589  118969.430321\n",
       "1589  1590   91049.863032\n",
       "1590  1591  126232.935861\n",
       "1591  1592  162015.411613\n",
       "1592  1593  200053.285967\n",
       "1593  1594  124284.098579\n",
       "1594  1595  279474.587195\n",
       "1595  1596  191975.460336\n",
       "1596  1597  214481.349024\n",
       "1597  1598  219464.719746\n",
       "1598  1599  156464.201680\n",
       "1599  1600  156505.654816\n",
       "1600  1601  440538.447326\n",
       "1601  1602   54727.813283\n",
       "1602  1603  168316.355027\n",
       "1603  1604  166320.339832\n",
       "1604  1605  144306.797318\n",
       "1605  1606   88349.143390\n",
       "1606  1607  194643.922521\n",
       "1607  1608  212470.184375\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_del&bin20.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test_del&bin20.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction.to_csv(\"Day18_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>95325.273830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>167363.188087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>137044.936774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>182289.933429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>153357.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>332427.369852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>131618.201473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>258126.239846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>119280.819446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>132829.365880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>140689.383793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>144701.526095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>178877.541707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>254093.667277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>137276.640855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>112665.579247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>227319.201935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>76518.771803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>173168.674446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>135376.151562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>284569.805130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>189186.739291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>140384.706379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>130495.413476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>129957.040620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>139856.973126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>168114.233508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>123405.960635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>218852.767453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>284734.162320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>232939.131826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>266008.750903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>147493.942658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>195163.290950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>115848.681977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>289007.122863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>240801.861455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>169327.949440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>143451.960781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>152964.797138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>126356.312524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>93561.812928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>127700.094024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>160763.225226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>198554.899240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>119007.165452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>278385.782523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>190969.566654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>216084.138302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>219154.961989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>164461.477952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>153442.498733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>452559.203171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>54001.528722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>163834.627577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>166256.795402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>149251.330896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>88145.539169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>198433.160071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>212247.740408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   95325.273830\n",
       "1        2  167363.188087\n",
       "2        3  137044.936774\n",
       "3        4  182289.933429\n",
       "4        5  153357.450700\n",
       "5        6  332427.369852\n",
       "6        7  131618.201473\n",
       "7        8  258126.239846\n",
       "8        9  119280.819446\n",
       "9       10  132829.365880\n",
       "10      11  140689.383793\n",
       "11      12  144701.526095\n",
       "12      13  178877.541707\n",
       "13      14  254093.667277\n",
       "14      15  137276.640855\n",
       "15      16  112665.579247\n",
       "16      17  227319.201935\n",
       "17      18   76518.771803\n",
       "18      19  173168.674446\n",
       "19      20  135376.151562\n",
       "20      21  284569.805130\n",
       "21      22  189186.739291\n",
       "22      23  140384.706379\n",
       "23      24  130495.413476\n",
       "24      25  129957.040620\n",
       "25      26  139856.973126\n",
       "26      27  168114.233508\n",
       "27      28  123405.960635\n",
       "28      29  218852.767453\n",
       "29      30  284734.162320\n",
       "...    ...            ...\n",
       "1578  1579  232939.131826\n",
       "1579  1580  266008.750903\n",
       "1580  1581  147493.942658\n",
       "1581  1582  195163.290950\n",
       "1582  1583  115848.681977\n",
       "1583  1584  289007.122863\n",
       "1584  1585  240801.861455\n",
       "1585  1586  169327.949440\n",
       "1586  1587  143451.960781\n",
       "1587  1588  152964.797138\n",
       "1588  1589  126356.312524\n",
       "1589  1590   93561.812928\n",
       "1590  1591  127700.094024\n",
       "1591  1592  160763.225226\n",
       "1592  1593  198554.899240\n",
       "1593  1594  119007.165452\n",
       "1594  1595  278385.782523\n",
       "1595  1596  190969.566654\n",
       "1596  1597  216084.138302\n",
       "1597  1598  219154.961989\n",
       "1598  1599  164461.477952\n",
       "1599  1600  153442.498733\n",
       "1600  1601  452559.203171\n",
       "1601  1602   54001.528722\n",
       "1602  1603  163834.627577\n",
       "1603  1604  166256.795402\n",
       "1604  1605  149251.330896\n",
       "1605  1606   88145.539169\n",
       "1606  1607  198433.160071\n",
       "1607  1608  212247.740408\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction3 = ((0.25*np.exp(prediction))+(0.25*np.exp(predFinalBoost))+(0.25*np.exp(y_pred_rg) + (0.25*np.exp(predforward))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction3 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction3})\n",
    "#Saving results into CSV file \n",
    "prediction3.to_csv(\"Day18_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>95508.953541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>167805.209174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>137128.663733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>182275.655525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>154853.808765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>331031.073723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>132021.923390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>262166.501665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>119710.121670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>132216.502149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>140584.587034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>144366.902686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>178523.929831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>253108.554414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>136754.937554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>112043.621435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>227772.923998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>77380.163327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>172855.266335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>135588.886859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>284690.459410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>189012.268424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>140032.392929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>129628.764497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>130359.464360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>139701.402758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>168715.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>122845.994708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>219459.501998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>289280.763627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>232867.631978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>265453.099440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>147268.414124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>193973.445139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>115642.808722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>289939.941122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>241918.485773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>168510.763385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>142721.059687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>151970.178926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>124992.055317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>93528.216167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>127428.851398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>160543.780963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>198493.501139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>119680.685113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>279059.884623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>192240.043243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>215875.885480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>220402.990047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>165370.154686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>152913.017041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>450066.578992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>52332.408366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>163072.217615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>166230.418308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>148811.359884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>89053.728751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>197712.511336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>212124.736915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   95508.953541\n",
       "1        2  167805.209174\n",
       "2        3  137128.663733\n",
       "3        4  182275.655525\n",
       "4        5  154853.808765\n",
       "5        6  331031.073723\n",
       "6        7  132021.923390\n",
       "7        8  262166.501665\n",
       "8        9  119710.121670\n",
       "9       10  132216.502149\n",
       "10      11  140584.587034\n",
       "11      12  144366.902686\n",
       "12      13  178523.929831\n",
       "13      14  253108.554414\n",
       "14      15  136754.937554\n",
       "15      16  112043.621435\n",
       "16      17  227772.923998\n",
       "17      18   77380.163327\n",
       "18      19  172855.266335\n",
       "19      20  135588.886859\n",
       "20      21  284690.459410\n",
       "21      22  189012.268424\n",
       "22      23  140032.392929\n",
       "23      24  129628.764497\n",
       "24      25  130359.464360\n",
       "25      26  139701.402758\n",
       "26      27  168715.813100\n",
       "27      28  122845.994708\n",
       "28      29  219459.501998\n",
       "29      30  289280.763627\n",
       "...    ...            ...\n",
       "1578  1579  232867.631978\n",
       "1579  1580  265453.099440\n",
       "1580  1581  147268.414124\n",
       "1581  1582  193973.445139\n",
       "1582  1583  115642.808722\n",
       "1583  1584  289939.941122\n",
       "1584  1585  241918.485773\n",
       "1585  1586  168510.763385\n",
       "1586  1587  142721.059687\n",
       "1587  1588  151970.178926\n",
       "1588  1589  124992.055317\n",
       "1589  1590   93528.216167\n",
       "1590  1591  127428.851398\n",
       "1591  1592  160543.780963\n",
       "1592  1593  198493.501139\n",
       "1593  1594  119680.685113\n",
       "1594  1595  279059.884623\n",
       "1595  1596  192240.043243\n",
       "1596  1597  215875.885480\n",
       "1597  1598  220402.990047\n",
       "1598  1599  165370.154686\n",
       "1599  1600  152913.017041\n",
       "1600  1601  450066.578992\n",
       "1601  1602   52332.408366\n",
       "1602  1603  163072.217615\n",
       "1603  1604  166230.418308\n",
       "1604  1605  148811.359884\n",
       "1605  1606   89053.728751\n",
       "1606  1607  197712.511336\n",
       "1607  1608  212124.736915\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(data, np.ravel(y_price)) \n",
    "pred_L_final = lasso.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 117625.3068124 ,  154406.58809745,  135270.46006291, ...,\n",
       "        106935.400622  ,  164524.5301393 ,  224045.45467818])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(pred_L_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(data,y_price)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction4 = ((np.exp(predFinalExtRandomForestlad)*(1/5))+(np.exp(prediction)*(1/5))+(np.exp(predFinalBoost)*(1/5))+(np.exp(y_pred_rg)*(1/5)) + (np.exp(predforward)*(1/5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  97623.67532531,  159917.41864414,  133822.27050019, ...,\n",
       "         92461.51084685,  189523.84021274,  215180.31456205])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalprediction4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction4 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction4})\n",
    "#Saving results into CSV file \n",
    "prediction4.to_csv(\"Day18_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
