{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from ExtraCode import getResultTable\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from QBUS2820 import forward\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from QBUS2820 import pcrCV\n",
    "from QBUS2820 import plsCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_Sep16_100.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "method = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(final_train, y_train)\n",
    "predforward = fwd.predict(final_test)\n",
    "method.append('Forward')\n",
    "pred.append(np.exp(predforward))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(final_train,y_train)\n",
    "predFinalBoost = GBoost.predict(final_test)\n",
    "method.append('GBoost')\n",
    "pred.append(np.exp(predFinalBoost))\n",
    "\n",
    "regr = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "method.append('AdaBoost')\n",
    "pred.append(np.exp(adapred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "testFinaldmat = xgb.DMatrix(final_test)\n",
    "xgpred = final_gb.predict(testFinaldmat)\n",
    "method.append('XGBoost')\n",
    "pred.append(np.exp(xgpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = (np.exp(xgpred)+np.exp(adapred)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred2)\n",
    "method.append('XGBoost, ada, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = (np.exp(xgpred)+np.exp(predFinalBoost))/2\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(adapred))/2\n",
    "pred.append(pred3)\n",
    "pred.append(pred5)\n",
    "method.append('xg GB')\n",
    "method.append('xg adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(final_train,y_train)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(final_test)\n",
    "pred.append(np.exp(predFinalExtRandomForestlad))\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred5 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred5)\n",
    "method.append('XGBoost, random tree, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred6 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad))/2\n",
    "pred.append(pred6)\n",
    "method.append('xg Random tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred10 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred10)\n",
    "method.append('XGBoost, GBoost Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(final_train, np.ravel(y_train)) \n",
    "pred_L = lasso.predict(final_test)\n",
    "method.append('LASSO')\n",
    "pred.append(np.exp(pred_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(final_train, y_train)\n",
    "y_pred_rg = (rg.predict(final_test))\n",
    "y_pred_rg\n",
    "\n",
    "pred.append(np.exp(y_pred_rg))\n",
    "method.append('Ridge alpha 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred11 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4\n",
    "pred.append(pred11)\n",
    "method.append('XGBoost, GBoost Random Forest Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred_L))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regr = ElasticNet(random_state=0, alpha = 1)\n",
    "    \n",
    "regr.fit(final_train, y_train)    \n",
    "pred13 = regr.predict(final_test)\n",
    "pred.append(np.exp(pred13))\n",
    "method.append('ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred13))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred13 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg))/3\n",
    "pred.append(pred13)\n",
    "method.append('XGBoost, GBoost Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred14 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward))/4\n",
    "pred.append(pred14)\n",
    "method.append('XGBoost, GBoost Ridge Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(pred_L))/5\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+ np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost, RandomTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred15 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = ((0.4*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward 40 40 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred17 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred17)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred18 = ((0.35*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.15*np.exp(y_pred_rg))+(0.15*np.exp(predforward)))\n",
    "pred.append(pred18)\n",
    "method.append('XGBoost, GBoost Ridge Forward 35 35 15 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred19 = ((0.25*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred19)\n",
    "method.append('XGBoost, GBoost Ridge Forward 25 35 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred20 = ((0.2*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred20)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 40 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred21 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred21)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 20 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred22 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred22)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 30 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred23 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred23)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.3*np.exp(xgpred))+(0.5*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 50 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.4*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 20 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred25 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred25)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 30 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred26 = ((0.26*np.exp(xgpred))+(0.27*np.exp(predFinalBoost))+(0.27*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred26)\n",
    "method.append('XGBoost, GBoost Ridge Forward 26 27 27 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred27 = ((0.23*np.exp(xgpred))+(0.24*np.exp(predFinalBoost))+(0.24*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred27)\n",
    "method.append('XGBoost, GBoost Ridge Forward 23 24 24 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred28 = ((0.15*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.35*np.exp(predforward))+(0.05*np.exp(predFinalExtRandomForestlad)))\n",
    "pred.append(pred28)\n",
    "method.append('XGBoost, GBoost Ridge Forward 15 35 10 35 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN with optimal 13</th>\n",
       "      <td>51782.470</td>\n",
       "      <td>4204.031</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.051</td>\n",
       "      <td>34870.104</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>17257.068</td>\n",
       "      <td>1022.512</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12609.981</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>20485.291</td>\n",
       "      <td>2407.912</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.012</td>\n",
       "      <td>13913.047</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>26595.357</td>\n",
       "      <td>4173.676</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.029</td>\n",
       "      <td>17596.954</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>18890.634</td>\n",
       "      <td>2190.922</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.011</td>\n",
       "      <td>13370.505</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>20251.802</td>\n",
       "      <td>3139.789</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.017</td>\n",
       "      <td>13315.056</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>18830.294</td>\n",
       "      <td>2372.399</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12870.380</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>21362.976</td>\n",
       "      <td>3369.138</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.019</td>\n",
       "      <td>14162.534</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>26504.080</td>\n",
       "      <td>4087.175</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.028</td>\n",
       "      <td>17446.002</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>20238.761</td>\n",
       "      <td>3108.765</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.017</td>\n",
       "      <td>13271.547</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>21297.063</td>\n",
       "      <td>3327.874</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.019</td>\n",
       "      <td>14066.919</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>20238.761</td>\n",
       "      <td>3108.765</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.017</td>\n",
       "      <td>13271.547</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>38336.162</td>\n",
       "      <td>10683.685</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.150</td>\n",
       "      <td>20422.339</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>15655.390</td>\n",
       "      <td>856.353</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.009</td>\n",
       "      <td>11759.523</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>17979.916</td>\n",
       "      <td>2154.759</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12288.626</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>20691.623</td>\n",
       "      <td>2520.475</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.014</td>\n",
       "      <td>13714.869</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>37904.630</td>\n",
       "      <td>11463.567</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.156</td>\n",
       "      <td>19240.242</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>20660.623</td>\n",
       "      <td>2623.290</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.014</td>\n",
       "      <td>13556.630</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>16665.960</td>\n",
       "      <td>1446.567</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11923.254</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>15763.783</td>\n",
       "      <td>1005.972</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11464.222</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>16667.659</td>\n",
       "      <td>1521.658</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11715.526</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Lasso</th>\n",
       "      <td>17455.234</td>\n",
       "      <td>1432.006</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12164.389</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost, RandomTree</th>\n",
       "      <td>20238.761</td>\n",
       "      <td>3108.765</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.017</td>\n",
       "      <td>13271.547</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 20 20</th>\n",
       "      <td>16174.655</td>\n",
       "      <td>1208.388</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11614.260</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 40 40 10 10</th>\n",
       "      <td>17320.673</td>\n",
       "      <td>1741.939</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12132.655</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>15473.243</td>\n",
       "      <td>863.497</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11364.536</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 35 35 15 15</th>\n",
       "      <td>16696.978</td>\n",
       "      <td>1458.029</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11832.338</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 25 35 20 20</th>\n",
       "      <td>16253.959</td>\n",
       "      <td>1218.420</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11667.349</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 40 20 20</th>\n",
       "      <td>16353.480</td>\n",
       "      <td>1228.558</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11754.568</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 20 30</th>\n",
       "      <td>15849.001</td>\n",
       "      <td>1006.179</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11494.820</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 30 20</th>\n",
       "      <td>15844.595</td>\n",
       "      <td>1026.136</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11533.224</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>15473.243</td>\n",
       "      <td>863.497</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11364.536</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 50 10 10</th>\n",
       "      <td>17513.626</td>\n",
       "      <td>1761.419</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12244.918</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 20 40</th>\n",
       "      <td>15553.423</td>\n",
       "      <td>867.173</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11402.299</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 30 10</th>\n",
       "      <td>16226.819</td>\n",
       "      <td>1245.973</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11691.677</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 26 27 27 20</th>\n",
       "      <td>15884.838</td>\n",
       "      <td>1070.898</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.006</td>\n",
       "      <td>11523.579</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 23 24 24 30</th>\n",
       "      <td>15646.104</td>\n",
       "      <td>901.238</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11525.340</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 15 35 10 35 5</th>\n",
       "      <td>15646.104</td>\n",
       "      <td>901.238</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.007</td>\n",
       "      <td>11525.340</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Test RMSE         SE  Jack R2  \\\n",
       "KNN with optimal 13                          51782.470   4204.031    0.452   \n",
       "Forward                                      17257.068   1022.512    0.939   \n",
       "GBoost                                       20485.291   2407.912    0.914   \n",
       "AdaBoost                                     26595.357   4173.676    0.855   \n",
       "XGBoost                                      18890.634   2190.922    0.927   \n",
       "XGBoost, ada, GB                             20251.802   3139.789    0.916   \n",
       "xg GB                                        18830.294   2372.399    0.928   \n",
       "xg adaboost                                  21362.976   3369.138    0.907   \n",
       "Random Forest                                26504.080   4087.175    0.856   \n",
       "XGBoost, random tree, GB                     20238.761   3108.765    0.916   \n",
       "xg Random tree                               21297.063   3327.874    0.907   \n",
       "XGBoost, GBoost Random Forest                20238.761   3108.765    0.916   \n",
       "LASSO                                        38336.162  10683.685    0.700   \n",
       "Ridge alpha 10                               15655.390    856.353    0.950   \n",
       "XGBoost, GBoost Random Forest Ridge          17979.916   2154.759    0.934   \n",
       "XGBoost, GBoost Random Forest LASSO          20691.623   2520.475    0.913   \n",
       "ENET                                         37904.630  11463.567    0.706   \n",
       "XGBoost, GBoost Random Forest ENET           20660.623   2623.290    0.913   \n",
       "XGBoost, GBoost Ridge                        16665.960   1446.567    0.943   \n",
       "XGBoost, GBoost Ridge Forward                15763.783   1005.972    0.949   \n",
       "XGBoost, GBoost Ridge Forward Tree           16667.659   1521.658    0.943   \n",
       "XGBoost, GBoost Ridge Forward Lasso          17455.234   1432.006    0.938   \n",
       "XGBoost, GBoost, RandomTree                  20238.761   3108.765    0.916   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20    16174.655   1208.388    0.947   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10    17320.673   1741.939    0.939   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30    15473.243    863.497    0.951   \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15    16696.978   1458.029    0.943   \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20    16253.959   1218.420    0.946   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20    16353.480   1228.558    0.945   \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30    15849.001   1006.179    0.949   \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20    15844.595   1026.136    0.949   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30    15473.243    863.497    0.951   \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10    17513.626   1761.419    0.937   \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40    15553.423    867.173    0.951   \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10    16226.819   1245.973    0.946   \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20    15884.838   1070.898    0.948   \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30    15646.104    901.238    0.950   \n",
       "XGBoost, GBoost Ridge Forward 15 35 10 35 5  15646.104    901.238    0.950   \n",
       "\n",
       "                                                SE        MAE  R-square  \n",
       "KNN with optimal 13                          0.051  34870.104     0.452  \n",
       "Forward                                      0.012  12609.981     0.939  \n",
       "GBoost                                       0.012  13913.047     0.914  \n",
       "AdaBoost                                     0.029  17596.954     0.855  \n",
       "XGBoost                                      0.011  13370.505     0.927  \n",
       "XGBoost, ada, GB                             0.017  13315.056     0.916  \n",
       "xg GB                                        0.011  12870.380     0.928  \n",
       "xg adaboost                                  0.019  14162.534     0.907  \n",
       "Random Forest                                0.028  17446.002     0.856  \n",
       "XGBoost, random tree, GB                     0.017  13271.547     0.916  \n",
       "xg Random tree                               0.019  14066.919     0.907  \n",
       "XGBoost, GBoost Random Forest                0.017  13271.547     0.916  \n",
       "LASSO                                        0.150  20422.339     0.700  \n",
       "Ridge alpha 10                               0.009  11759.523     0.950  \n",
       "XGBoost, GBoost Random Forest Ridge          0.010  12288.626     0.934  \n",
       "XGBoost, GBoost Random Forest LASSO          0.014  13714.869     0.913  \n",
       "ENET                                         0.156  19240.242     0.706  \n",
       "XGBoost, GBoost Random Forest ENET           0.014  13556.630     0.913  \n",
       "XGBoost, GBoost Ridge                        0.006  11923.254     0.943  \n",
       "XGBoost, GBoost Ridge Forward                0.006  11464.222     0.949  \n",
       "XGBoost, GBoost Ridge Forward Tree           0.006  11715.526     0.943  \n",
       "XGBoost, GBoost Ridge Forward Lasso          0.010  12164.389     0.938  \n",
       "XGBoost, GBoost, RandomTree                  0.017  13271.547     0.916  \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20    0.006  11614.260     0.947  \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10    0.008  12132.655     0.939  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30    0.007  11364.536     0.951  \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15    0.006  11832.338     0.943  \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20    0.006  11667.349     0.946  \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20    0.006  11754.568     0.945  \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30    0.006  11494.820     0.949  \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20    0.006  11533.224     0.949  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30    0.007  11364.536     0.951  \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10    0.008  12244.918     0.937  \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40    0.007  11402.299     0.951  \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10    0.006  11691.677     0.946  \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20    0.006  11523.579     0.948  \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30    0.007  11525.340     0.950  \n",
       "XGBoost, GBoost Ridge Forward 15 35 10 35 5  0.007  11525.340     0.950  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResultTable(rows, predictions):\n",
    "    columns=['Test RMSE', 'SE', 'Jack R2', 'SE', 'MAE', 'R-square']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        results.iloc[row,0], results.iloc[row,1] = rmse_jack(y_test, pred)\n",
    "        results.iloc[row,2], results.iloc[row,3] = (r2_jack(y_test, pred))\n",
    "        results.iloc[row,4] = mean_absolute_error(y_test, pred)\n",
    "        results.iloc[row,5] = r2_score(y_test,pred)\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_Sep15_339.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test_Sep15_339.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr2.fit(data,y_price)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = ((0.15*np.exp(prediction))+(0.35*np.exp(predFinalBoost))+(0.05*np.exp(y_pred_rg))+ (np.exp(predFinalExtRandomForestlad)*0.1) + (0.35*np.exp(predforward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction2 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction2.to_csv(\"Day16_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98906.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164653.486277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>132449.692489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>192799.050091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>154056.623731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>314764.125762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>132726.565154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>259260.811059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>119481.582105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>129214.088846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>138154.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>143324.589438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>176975.174222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>247773.871223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>142979.277925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>109626.670599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>221995.620209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>75434.242683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>176744.817034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>136085.022397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>283166.689015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>190947.342746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>141013.314728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>128716.136798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>131900.913749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>139388.282587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>172555.674312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>121057.623972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>214264.516350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>288419.208567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>229856.663458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>255944.631913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>146589.187193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>199605.035178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>119173.448814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>302292.616471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>240244.749755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>172407.218867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>142093.798359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>150532.266679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>124392.873215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>88808.699535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>128314.799888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>160684.372223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>204596.897610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>118663.940955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>283885.750222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>195973.461432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>213270.305245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>224829.328767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>180620.959653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>155761.538735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>434417.108608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>51881.090624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>169678.968971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>166568.301075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>151947.527147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>86668.886128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>194622.409657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>207717.865682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   98906.662300\n",
       "1        2  164653.486277\n",
       "2        3  132449.692489\n",
       "3        4  192799.050091\n",
       "4        5  154056.623731\n",
       "5        6  314764.125762\n",
       "6        7  132726.565154\n",
       "7        8  259260.811059\n",
       "8        9  119481.582105\n",
       "9       10  129214.088846\n",
       "10      11  138154.001355\n",
       "11      12  143324.589438\n",
       "12      13  176975.174222\n",
       "13      14  247773.871223\n",
       "14      15  142979.277925\n",
       "15      16  109626.670599\n",
       "16      17  221995.620209\n",
       "17      18   75434.242683\n",
       "18      19  176744.817034\n",
       "19      20  136085.022397\n",
       "20      21  283166.689015\n",
       "21      22  190947.342746\n",
       "22      23  141013.314728\n",
       "23      24  128716.136798\n",
       "24      25  131900.913749\n",
       "25      26  139388.282587\n",
       "26      27  172555.674312\n",
       "27      28  121057.623972\n",
       "28      29  214264.516350\n",
       "29      30  288419.208567\n",
       "...    ...            ...\n",
       "1578  1579  229856.663458\n",
       "1579  1580  255944.631913\n",
       "1580  1581  146589.187193\n",
       "1581  1582  199605.035178\n",
       "1582  1583  119173.448814\n",
       "1583  1584  302292.616471\n",
       "1584  1585  240244.749755\n",
       "1585  1586  172407.218867\n",
       "1586  1587  142093.798359\n",
       "1587  1588  150532.266679\n",
       "1588  1589  124392.873215\n",
       "1589  1590   88808.699535\n",
       "1590  1591  128314.799888\n",
       "1591  1592  160684.372223\n",
       "1592  1593  204596.897610\n",
       "1593  1594  118663.940955\n",
       "1594  1595  283885.750222\n",
       "1595  1596  195973.461432\n",
       "1596  1597  213270.305245\n",
       "1597  1598  224829.328767\n",
       "1598  1599  180620.959653\n",
       "1599  1600  155761.538735\n",
       "1600  1601  434417.108608\n",
       "1601  1602   51881.090624\n",
       "1602  1603  169678.968971\n",
       "1603  1604  166568.301075\n",
       "1604  1605  151947.527147\n",
       "1605  1606   86668.886128\n",
       "1606  1607  194622.409657\n",
       "1607  1608  207717.865682\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction2 = ((0.2*np.exp(prediction))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+  + (0.3*np.exp(predforward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction3 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction2})\n",
    "#Saving results into CSV file \n",
    "prediction3.to_csv(\"Day16_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98989.590658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>163711.477489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>133656.097285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>188943.861283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>154962.226879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>336998.542361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>131940.387678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>263924.563792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>118205.901269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>133959.130509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>140471.517755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>142729.554965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>173861.640373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>252710.549406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>139381.645501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>110368.300887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>228223.764865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>77782.441318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>175617.610976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>136059.694449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>283469.768449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>189315.744771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>138668.504334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>125198.926763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>131947.031465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>140571.456572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>171132.580248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>121119.879157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>214353.706249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>289579.604236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>232247.033855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>257827.608410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>147898.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>196432.167994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>120130.769904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>295060.005241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>237427.084904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>168380.297629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>141296.319592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>151065.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>125428.952199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>89831.162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>125374.332693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>161067.357504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>206101.093711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>121148.421495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>287824.071209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>193598.778084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>215156.647122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>227056.315432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>174253.076588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>153931.076569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>448892.608001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>52956.937608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>166054.165946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>163831.216062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>150194.057346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>85572.653912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>193894.456183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>211064.666946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   98989.590658\n",
       "1        2  163711.477489\n",
       "2        3  133656.097285\n",
       "3        4  188943.861283\n",
       "4        5  154962.226879\n",
       "5        6  336998.542361\n",
       "6        7  131940.387678\n",
       "7        8  263924.563792\n",
       "8        9  118205.901269\n",
       "9       10  133959.130509\n",
       "10      11  140471.517755\n",
       "11      12  142729.554965\n",
       "12      13  173861.640373\n",
       "13      14  252710.549406\n",
       "14      15  139381.645501\n",
       "15      16  110368.300887\n",
       "16      17  228223.764865\n",
       "17      18   77782.441318\n",
       "18      19  175617.610976\n",
       "19      20  136059.694449\n",
       "20      21  283469.768449\n",
       "21      22  189315.744771\n",
       "22      23  138668.504334\n",
       "23      24  125198.926763\n",
       "24      25  131947.031465\n",
       "25      26  140571.456572\n",
       "26      27  171132.580248\n",
       "27      28  121119.879157\n",
       "28      29  214353.706249\n",
       "29      30  289579.604236\n",
       "...    ...            ...\n",
       "1578  1579  232247.033855\n",
       "1579  1580  257827.608410\n",
       "1580  1581  147898.797604\n",
       "1581  1582  196432.167994\n",
       "1582  1583  120130.769904\n",
       "1583  1584  295060.005241\n",
       "1584  1585  237427.084904\n",
       "1585  1586  168380.297629\n",
       "1586  1587  141296.319592\n",
       "1587  1588  151065.043700\n",
       "1588  1589  125428.952199\n",
       "1589  1590   89831.162362\n",
       "1590  1591  125374.332693\n",
       "1591  1592  161067.357504\n",
       "1592  1593  206101.093711\n",
       "1593  1594  121148.421495\n",
       "1594  1595  287824.071209\n",
       "1595  1596  193598.778084\n",
       "1596  1597  215156.647122\n",
       "1597  1598  227056.315432\n",
       "1598  1599  174253.076588\n",
       "1599  1600  153931.076569\n",
       "1600  1601  448892.608001\n",
       "1601  1602   52956.937608\n",
       "1602  1603  166054.165946\n",
       "1603  1604  163831.216062\n",
       "1604  1605  150194.057346\n",
       "1605  1606   85572.653912\n",
       "1606  1607  193894.456183\n",
       "1607  1608  211064.666946\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_Sep16_100.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test_Sep16_100.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))\n",
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction3 = ((0.2*np.exp(prediction))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+  + (0.3*np.exp(predforward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction3 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction3})\n",
    "#Saving results into CSV file \n",
    "prediction3.to_csv(\"Day16_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction4 = y_pred_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction4 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction4})\n",
    "#Saving results into CSV file \n",
    "prediction4.to_csv(\"Day16_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction5 = ((0.2*np.exp(prediction))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+  + (0.2*np.exp(predforward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction5})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day17_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
