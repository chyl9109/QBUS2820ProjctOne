{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from ExtraCode import getResultTable\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from QBUS2820 import forward\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's ok..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "method = []\n",
    "\n",
    "data = pd.read_csv('Train6_2.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "\n",
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(final_train, y_train)\n",
    "predforward = fwd.predict(final_test)\n",
    "method.append('Forward')\n",
    "pred.append(np.exp(predforward))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(final_train,y_train)\n",
    "predFinalBoost = GBoost.predict(final_test)\n",
    "method.append('GBoost')\n",
    "pred.append(np.exp(predFinalBoost))\n",
    "\n",
    "regr = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "method.append('AdaBoost')\n",
    "pred.append(np.exp(adapred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "testFinaldmat = xgb.DMatrix(final_test)\n",
    "xgpred = final_gb.predict(testFinaldmat)\n",
    "method.append('XGBoost')\n",
    "pred.append(np.exp(xgpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = (np.exp(xgpred)+np.exp(adapred)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred2)\n",
    "method.append('XGBoost, ada, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = (np.exp(xgpred)+np.exp(predFinalBoost))/2\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(adapred))/2\n",
    "pred.append(pred3)\n",
    "pred.append(pred5)\n",
    "method.append('xg GB')\n",
    "method.append('xg adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predFinalExtRandomForestlad = regr.predict(final_test)\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred5)\n",
    "method.append('XGBoost, random tree, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred6 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad))/2\n",
    "pred.append(pred6)\n",
    "method.append('xg Random tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred10 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred10)\n",
    "method.append('XGBoost, GBoost Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 10\n",
    "def RMSLE(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(final_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, final_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LASSO\n",
    "level = [0.1, 1, 5, 10, 20, 50, 75, 100]\n",
    "for x in level:\n",
    "    lasso = Lasso(alpha = x)\n",
    "    lasso.fit(final_train, y_train) \n",
    "    pred_L = lasso.predict(final_test)\n",
    "    method.append('LASSO_Alpha')\n",
    "    pred.append(np.exp(pred_L))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.1 the Lasso model accuracy score = 96.55 and  mean rmse = 21741.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 1 the Lasso model accuracy score = 96.55 and  mean rmse = 21457.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 5 the Lasso model accuracy score = 96.52 and  mean rmse = 20668.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10 the Lasso model accuracy score = 96.47 and  mean rmse = 20068.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 20 the Lasso model accuracy score = 96.32 and  mean rmse = 19344.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 50 the Lasso model accuracy score = 95.97 and  mean rmse = 18617.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 75 the Lasso model accuracy score = 95.75 and  mean rmse = 18496.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 100 the Lasso model accuracy score = 95.58 and  mean rmse = 18508.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alphas = [0.1, 1, 5, 10, 20, 50, 75, 100]\n",
    "for alpha in alphas:\n",
    "    rg = Lasso(alpha = alpha)\n",
    "    rg.fit(final_train, y_train)\n",
    "    rg_score = rg.score(final_train, y_train)\n",
    "    rmse = RMSLE(rg).mean()\n",
    "    print(\"For alpha = {} the Lasso model accuracy score = {:.2f} and  mean rmse = {:.3f}\".format(alpha, rg_score*100, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=y_train.mean()\n",
    "sigma=y_train.std() \n",
    "standardPrice=(y_train-mu)/sigma\n",
    "\n",
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(final_train, np.ravel(standardPrice)) \n",
    "pred_L = lasso.predict(final_test)\n",
    "predFinalLasso = (pred_L*sigma) + mu\n",
    "method.append('LASSO Standard')\n",
    "pred.append(predFinalLasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.001 the Ridge model accuracy score = 96.55 and  mean rmse = 21717.670\n",
      "For alpha = 0.01 the Ridge model accuracy score = 96.55 and  mean rmse = 21574.424\n",
      "For alpha = 0.1 the Ridge model accuracy score = 96.53 and  mean rmse = 20767.142\n",
      "For alpha = 1 the Ridge model accuracy score = 96.31 and  mean rmse = 19317.776\n",
      "For alpha = 5 the Ridge model accuracy score = 95.78 and  mean rmse = 18998.876\n",
      "For alpha = 10 the Ridge model accuracy score = 95.40 and  mean rmse = 19176.510\n",
      "For alpha = 20 the Ridge model accuracy score = 94.92 and  mean rmse = 19516.232\n",
      "For alpha = 50 the Ridge model accuracy score = 94.14 and  mean rmse = 20174.935\n",
      "For alpha = 75 the Ridge model accuracy score = 93.74 and  mean rmse = 20549.666\n",
      "For alpha = 100 the Ridge model accuracy score = 93.44 and  mean rmse = 20853.185\n"
     ]
    }
   ],
   "source": [
    "#RIDGE\n",
    "#alphas = np.exp(np.linspace(-10,20,500)) \n",
    "#ridge = RidgeCV(alphas=alphas, cv=10)\n",
    "#ridge.fit(final_train, y_train)\n",
    "#ridge = Ridge(alpha=ridge.alpha_)\n",
    "#ridge.fit(final_train, y_train)\n",
    "#pred_R = ridge.predict(final_test)\n",
    "#method.append('Ridge')\n",
    "#pred.append(pred_R)\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 5, 10, 20, 50, 75, 100]\n",
    "for alpha in alphas:\n",
    "    rg = Ridge(alpha = alpha)\n",
    "    rg.fit(final_train, y_train)\n",
    "    rg_score = rg.score(final_train, y_train)\n",
    "    rmse = RMSLE(rg).mean()\n",
    "    print(\"For alpha = {} the Ridge model accuracy score = {:.2f} and  mean rmse = {:.3f}\".format(alpha, rg_score*100, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 20\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(final_train, y_train)\n",
    "y_pred_rg = (rg.predict(final_test))\n",
    "y_pred_rg\n",
    "\n",
    "pred.append(np.exp(y_pred_rg))\n",
    "method.append('Ridge alpha 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RIDGE standard 1\n",
    "alphas = np.exp(np.linspace(-10,20,500)) \n",
    "ridge = RidgeCV(alphas=alphas, cv=10)\n",
    "ridge.fit(final_train, np.ravel(standardPrice))\n",
    "ridge = Ridge(alpha=ridge.alpha_)\n",
    "ridge.fit(final_train, np.ravel(standardPrice))\n",
    "pred_R = ridge.predict(final_test)\n",
    "predFinalRidge = (pred_R*sigma) + mu\n",
    "method.append('Ridge Standard1')\n",
    "pred.append(predFinalRidge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ridge standard 2\n",
    "alphas = np.exp(np.linspace(-10,20,500))\n",
    "\n",
    "ridge = RidgeCV(alphas=alphas, cv=10)\n",
    "ridge.fit(final_train, np.ravel(standardPrice))\n",
    "ridge = Ridge(alpha=ridge.alpha_)\n",
    "ridge.fit(final_train, np.ravel(standardPrice))\n",
    "pred_R = ridge.predict(final_test)\n",
    "predFinalRidge = (pred_R*sigma) + mu\n",
    "method.append('Ridge Standard1')\n",
    "pred.append(predFinalRidge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred11 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4\n",
    "pred.append(pred11)\n",
    "method.append('XGBoost, GBoost Random Forest Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred_L))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "regr = ElasticNet(random_state=0, alpha = 1)\n",
    "    \n",
    "regr.fit(final_train, y_train)    \n",
    "pred13 = regr.predict(final_test)\n",
    "pred.append(np.exp(pred13))\n",
    "method.append('ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (xgpred+predFinalBoost+predFinalExtRandomForestlad+pred13)/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred13 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg))/3\n",
    "pred.append(pred13)\n",
    "method.append('XGBoost, GBoost Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred14 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward))/4\n",
    "pred.append(pred14)\n",
    "method.append('XGBoost, GBoost Ridge Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>23834.417</td>\n",
       "      <td>4933.468</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.047</td>\n",
       "      <td>14042.658</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>20918.845</td>\n",
       "      <td>3335.212</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.019</td>\n",
       "      <td>13764.739</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>26396.260</td>\n",
       "      <td>3445.265</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.023</td>\n",
       "      <td>18521.883</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>20930.701</td>\n",
       "      <td>3433.914</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13937.653</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>20990.748</td>\n",
       "      <td>3686.173</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.022</td>\n",
       "      <td>13907.523</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>20256.938</td>\n",
       "      <td>3491.853</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13369.483</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>22014.324</td>\n",
       "      <td>3690.781</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.023</td>\n",
       "      <td>14815.195</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>21014.092</td>\n",
       "      <td>3760.257</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.022</td>\n",
       "      <td>13862.684</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>21990.427</td>\n",
       "      <td>3808.881</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.023</td>\n",
       "      <td>14686.106</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>21014.092</td>\n",
       "      <td>3760.257</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.022</td>\n",
       "      <td>13862.684</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha_zeropointone</th>\n",
       "      <td>33487.881</td>\n",
       "      <td>8253.967</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.104</td>\n",
       "      <td>18309.952</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>22958.587</td>\n",
       "      <td>4912.274</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.045</td>\n",
       "      <td>13610.797</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>18687.310</td>\n",
       "      <td>2274.773</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12983.717</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>20738.696</td>\n",
       "      <td>2924.153</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13959.306</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>34151.039</td>\n",
       "      <td>8005.147</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.103</td>\n",
       "      <td>18888.261</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>191867.789</td>\n",
       "      <td>5074.864</td>\n",
       "      <td>-6.523</td>\n",
       "      <td>0.916</td>\n",
       "      <td>178661.326</td>\n",
       "      <td>-6.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>18162.316</td>\n",
       "      <td>1732.004</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12735.517</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>18555.519</td>\n",
       "      <td>1777.839</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12743.404</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>18452.473</td>\n",
       "      <td>1817.337</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12912.083</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha_one</th>\n",
       "      <td>34657.818</td>\n",
       "      <td>7340.865</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.097</td>\n",
       "      <td>20087.645</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>33487.881</td>\n",
       "      <td>8253.967</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.104</td>\n",
       "      <td>18309.952</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>34657.818</td>\n",
       "      <td>7340.865</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.097</td>\n",
       "      <td>20087.645</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>35545.440</td>\n",
       "      <td>5477.616</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.080</td>\n",
       "      <td>23351.307</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>38610.035</td>\n",
       "      <td>7084.392</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.107</td>\n",
       "      <td>24220.423</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>47177.318</td>\n",
       "      <td>10181.112</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.180</td>\n",
       "      <td>28087.909</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>60827.358</td>\n",
       "      <td>18733.094</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.399</td>\n",
       "      <td>31701.143</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>75767.793</td>\n",
       "      <td>29097.395</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.737</td>\n",
       "      <td>35488.550</td>\n",
       "      <td>-0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO_Alpha</th>\n",
       "      <td>95091.167</td>\n",
       "      <td>43559.474</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>1.322</td>\n",
       "      <td>39790.477</td>\n",
       "      <td>-0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO Standard</th>\n",
       "      <td>191867.784</td>\n",
       "      <td>5074.863</td>\n",
       "      <td>-6.523</td>\n",
       "      <td>0.916</td>\n",
       "      <td>178661.321</td>\n",
       "      <td>-6.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Standard1</th>\n",
       "      <td>191867.781</td>\n",
       "      <td>5074.861</td>\n",
       "      <td>-6.523</td>\n",
       "      <td>0.916</td>\n",
       "      <td>178661.329</td>\n",
       "      <td>-6.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 5</th>\n",
       "      <td>22676.776</td>\n",
       "      <td>5832.693</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.050</td>\n",
       "      <td>12977.066</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 0.001</th>\n",
       "      <td>27154.854</td>\n",
       "      <td>5866.839</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.063</td>\n",
       "      <td>15361.573</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 0.01</th>\n",
       "      <td>26955.637</td>\n",
       "      <td>5788.133</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.062</td>\n",
       "      <td>15286.280</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>23009.669</td>\n",
       "      <td>6346.654</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12907.565</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 20</th>\n",
       "      <td>23532.883</td>\n",
       "      <td>6821.710</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.059</td>\n",
       "      <td>12935.975</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Test RMSE         SE  Jack R2     SE  \\\n",
       "Forward                               23834.417   4933.468    0.884  0.047   \n",
       "GBoost                                20918.845   3335.212    0.911  0.019   \n",
       "AdaBoost                              26396.260   3445.265    0.858  0.023   \n",
       "XGBoost                               20930.701   3433.914    0.910  0.020   \n",
       "XGBoost, ada, GB                      20990.748   3686.173    0.910  0.022   \n",
       "xg GB                                 20256.938   3491.853    0.916  0.020   \n",
       "xg adaboost                           22014.324   3690.781    0.901  0.023   \n",
       "XGBoost, random tree, GB              21014.092   3760.257    0.910  0.022   \n",
       "xg Random tree                        21990.427   3808.881    0.901  0.023   \n",
       "XGBoost, GBoost Random Forest         21014.092   3760.257    0.910  0.022   \n",
       "LASSO_Alpha_zeropointone              33487.881   8253.967    0.771  0.104   \n",
       "Ridge                                 22958.587   4912.274    0.892  0.045   \n",
       "XGBoost, GBoost Random Forest Ridge   18687.310   2274.773    0.929  0.011   \n",
       "XGBoost, GBoost Random Forest LASSO   20738.696   2924.153    0.912  0.016   \n",
       "ENET                                  34151.039   8005.147    0.762  0.103   \n",
       "XGBoost, GBoost Random Forest ENET   191867.789   5074.864   -6.523  0.916   \n",
       "XGBoost, GBoost Ridge                 18162.316   1732.004    0.933  0.009   \n",
       "XGBoost, GBoost Ridge Forward         18555.519   1777.839    0.930  0.012   \n",
       "XGBoost, GBoost Ridge Forward Tree    18452.473   1817.337    0.930  0.009   \n",
       "LASSO_Alpha_one                       34657.818   7340.865    0.755  0.097   \n",
       "LASSO_Alpha                           33487.881   8253.967    0.771  0.104   \n",
       "LASSO_Alpha                           34657.818   7340.865    0.755  0.097   \n",
       "LASSO_Alpha                           35545.440   5477.616    0.742  0.080   \n",
       "LASSO_Alpha                           38610.035   7084.392    0.695  0.107   \n",
       "LASSO_Alpha                           47177.318  10181.112    0.545  0.180   \n",
       "LASSO_Alpha                           60827.358  18733.094    0.244  0.399   \n",
       "LASSO_Alpha                           75767.793  29097.395   -0.173  0.737   \n",
       "LASSO_Alpha                           95091.167  43559.474   -0.848  1.322   \n",
       "LASSO Standard                       191867.784   5074.863   -6.523  0.916   \n",
       "Ridge Standard1                      191867.781   5074.861   -6.523  0.916   \n",
       "Ridge alpha 5                         22676.776   5832.693    0.895  0.050   \n",
       "Ridge alpha 0.001                     27154.854   5866.839    0.849  0.063   \n",
       "Ridge alpha 0.01                      26955.637   5788.133    0.852  0.062   \n",
       "Ridge alpha 10                        23009.669   6346.654    0.892  0.055   \n",
       "Ridge alpha 20                        23532.883   6821.710    0.887  0.059   \n",
       "\n",
       "                                            MAE  R-square  \n",
       "Forward                               14042.658     0.884  \n",
       "GBoost                                13764.739     0.911  \n",
       "AdaBoost                              18521.883     0.858  \n",
       "XGBoost                               13937.653     0.910  \n",
       "XGBoost, ada, GB                      13907.523     0.910  \n",
       "xg GB                                 13369.483     0.916  \n",
       "xg adaboost                           14815.195     0.901  \n",
       "XGBoost, random tree, GB              13862.684     0.910  \n",
       "xg Random tree                        14686.106     0.901  \n",
       "XGBoost, GBoost Random Forest         13862.684     0.910  \n",
       "LASSO_Alpha_zeropointone              18309.952     0.771  \n",
       "Ridge                                 13610.797     0.892  \n",
       "XGBoost, GBoost Random Forest Ridge   12983.717     0.929  \n",
       "XGBoost, GBoost Random Forest LASSO   13959.306     0.912  \n",
       "ENET                                  18888.261     0.762  \n",
       "XGBoost, GBoost Random Forest ENET   178661.326    -6.523  \n",
       "XGBoost, GBoost Ridge                 12735.517     0.933  \n",
       "XGBoost, GBoost Ridge Forward         12743.404     0.930  \n",
       "XGBoost, GBoost Ridge Forward Tree    12912.083     0.930  \n",
       "LASSO_Alpha_one                       20087.645     0.755  \n",
       "LASSO_Alpha                           18309.952     0.771  \n",
       "LASSO_Alpha                           20087.645     0.755  \n",
       "LASSO_Alpha                           23351.307     0.742  \n",
       "LASSO_Alpha                           24220.423     0.695  \n",
       "LASSO_Alpha                           28087.909     0.545  \n",
       "LASSO_Alpha                           31701.143     0.244  \n",
       "LASSO_Alpha                           35488.550    -0.173  \n",
       "LASSO_Alpha                           39790.477    -0.848  \n",
       "LASSO Standard                       178661.321    -6.523  \n",
       "Ridge Standard1                      178661.329    -6.523  \n",
       "Ridge alpha 5                         12977.066     0.895  \n",
       "Ridge alpha 0.001                     15361.573     0.849  \n",
       "Ridge alpha 0.01                      15286.280     0.852  \n",
       "Ridge alpha 10                        12907.565     0.892  \n",
       "Ridge alpha 20                        12935.975     0.887  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getResultTable(rows, predictions):\n",
    "    columns=['Test RMSE', 'SE', 'Jack R2', 'SE', 'MAE', 'R-square']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        results.iloc[row,0], results.iloc[row,1] = rmse_jack(y_test, pred)\n",
    "        results.iloc[row,2], results.iloc[row,3] = (r2_jack(y_test, pred))\n",
    "        results.iloc[row,4] = mean_absolute_error(y_test, pred)\n",
    "        results.iloc[row,5] = r2_score(y_test,pred)\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr = regr.fit(data,y_price)\n",
    "predFinalExtRandomForestlad = regr.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day6_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day7_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_2.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_2.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day7_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg)+np.exp(predforward))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day7_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day7_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 5\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg)+np.exp(predforward))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction5 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction5.to_csv(\"Day7_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
