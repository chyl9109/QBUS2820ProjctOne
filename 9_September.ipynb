{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from ExtraCode import getResultTable\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from QBUS2820 import forward\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "method = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "\n",
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(final_train, y_train)\n",
    "predforward = fwd.predict(final_test)\n",
    "method.append('Forward')\n",
    "pred.append(np.exp(predforward))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(final_train,y_train)\n",
    "predFinalBoost = GBoost.predict(final_test)\n",
    "method.append('GBoost')\n",
    "pred.append(np.exp(predFinalBoost))\n",
    "\n",
    "regr = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "method.append('AdaBoost')\n",
    "pred.append(np.exp(adapred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "testFinaldmat = xgb.DMatrix(final_test)\n",
    "xgpred = final_gb.predict(testFinaldmat)\n",
    "method.append('XGBoost')\n",
    "pred.append(np.exp(xgpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = (np.exp(xgpred)+np.exp(adapred)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred2)\n",
    "method.append('XGBoost, ada, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = (np.exp(xgpred)+np.exp(predFinalBoost))/2\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(adapred))/2\n",
    "pred.append(pred3)\n",
    "pred.append(pred5)\n",
    "method.append('xg GB')\n",
    "method.append('xg adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(final_train,y_train)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(final_test)\n",
    "pred.append(np.exp(predFinalExtRandomForestlad))\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred5 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred5)\n",
    "method.append('XGBoost, random tree, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred6 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad))/2\n",
    "pred.append(pred6)\n",
    "method.append('xg Random tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred10 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred10)\n",
    "method.append('XGBoost, GBoost Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(final_train, np.ravel(y_train)) \n",
    "pred_L = lasso.predict(final_test)\n",
    "method.append('LASSO')\n",
    "pred.append(np.exp(pred_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(final_train, y_train)\n",
    "y_pred_rg = (rg.predict(final_test))\n",
    "y_pred_rg\n",
    "\n",
    "pred.append(np.exp(y_pred_rg))\n",
    "method.append('Ridge alpha 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred11 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4\n",
    "pred.append(pred11)\n",
    "method.append('XGBoost, GBoost Random Forest Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred_L))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = ElasticNet(random_state=0, alpha = 1)\n",
    "    \n",
    "regr.fit(final_train, y_train)    \n",
    "pred13 = regr.predict(final_test)\n",
    "pred.append(np.exp(pred13))\n",
    "method.append('ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred13))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred13 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg))/3\n",
    "pred.append(pred13)\n",
    "method.append('XGBoost, GBoost Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred14 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward))/4\n",
    "pred.append(pred14)\n",
    "method.append('XGBoost, GBoost Ridge Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(pred_L))/5\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+ np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost, RandomTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred15 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = ((0.4*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward 40 40 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred17 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred17)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred18 = ((0.35*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.15*np.exp(y_pred_rg))+(0.15*np.exp(predforward)))\n",
    "pred.append(pred18)\n",
    "method.append('XGBoost, GBoost Ridge Forward 35 35 15 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred19 = ((0.25*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred19)\n",
    "method.append('XGBoost, GBoost Ridge Forward 25 35 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred20 = ((0.2*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred20)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 40 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred21 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred21)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 20 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred22 = ((0.2*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred22)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 30 30 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred23 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred23)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 30 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.3*np.exp(xgpred))+(0.5*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 50 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred24 = ((0.2*np.exp(xgpred))+(0.2*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.4*np.exp(predforward)))\n",
    "pred.append(pred24)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 20 20 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred25 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred25)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 30 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred26 = ((0.26*np.exp(xgpred))+(0.27*np.exp(predFinalBoost))+(0.27*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred26)\n",
    "method.append('XGBoost, GBoost Ridge Forward 26 27 27 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred27 = ((0.23*np.exp(xgpred))+(0.24*np.exp(predFinalBoost))+(0.24*np.exp(y_pred_rg))+(0.3*np.exp(predforward)))\n",
    "pred.append(pred27)\n",
    "method.append('XGBoost, GBoost Ridge Forward 23 24 24 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>23834.417</td>\n",
       "      <td>4933.468</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.047</td>\n",
       "      <td>14042.658</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>19401.538</td>\n",
       "      <td>2816.862</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.015</td>\n",
       "      <td>12968.305</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>26290.713</td>\n",
       "      <td>3510.404</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.023</td>\n",
       "      <td>18384.608</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>20400.397</td>\n",
       "      <td>3406.287</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13619.232</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>20358.669</td>\n",
       "      <td>3513.519</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13512.210</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>19250.267</td>\n",
       "      <td>3211.549</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.017</td>\n",
       "      <td>12745.760</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>21745.027</td>\n",
       "      <td>3713.139</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.023</td>\n",
       "      <td>14624.200</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>25875.535</td>\n",
       "      <td>3534.220</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.023</td>\n",
       "      <td>18050.721</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>20268.412</td>\n",
       "      <td>3515.703</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13428.969</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>21605.204</td>\n",
       "      <td>3717.447</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.022</td>\n",
       "      <td>14536.721</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>20268.412</td>\n",
       "      <td>3515.703</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13428.969</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>34657.818</td>\n",
       "      <td>7340.865</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.097</td>\n",
       "      <td>20087.645</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>23016.283</td>\n",
       "      <td>6348.168</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12901.650</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>18023.909</td>\n",
       "      <td>2135.523</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12574.029</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>20548.107</td>\n",
       "      <td>2930.692</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13845.466</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>34151.039</td>\n",
       "      <td>8005.147</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.103</td>\n",
       "      <td>18888.261</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>20399.404</td>\n",
       "      <td>2913.771</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13711.384</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>17281.535</td>\n",
       "      <td>1636.619</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12111.831</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>17862.469</td>\n",
       "      <td>1812.492</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12284.778</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>17883.572</td>\n",
       "      <td>1748.030</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12535.058</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Lasso</th>\n",
       "      <td>19715.427</td>\n",
       "      <td>2888.109</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.022</td>\n",
       "      <td>12719.451</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost, RandomTree</th>\n",
       "      <td>20268.412</td>\n",
       "      <td>3515.703</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13428.969</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 20 20</th>\n",
       "      <td>17571.955</td>\n",
       "      <td>1657.378</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12249.831</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 40 40 10 10</th>\n",
       "      <td>17862.755</td>\n",
       "      <td>2279.217</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12360.641</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>18429.855</td>\n",
       "      <td>2328.360</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.018</td>\n",
       "      <td>12353.008</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 35 35 15 15</th>\n",
       "      <td>17572.052</td>\n",
       "      <td>1869.569</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12275.339</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 25 35 20 20</th>\n",
       "      <td>17545.527</td>\n",
       "      <td>1643.278</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12248.799</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 40 20 20</th>\n",
       "      <td>17533.736</td>\n",
       "      <td>1628.856</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12260.901</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 20 30</th>\n",
       "      <td>17935.120</td>\n",
       "      <td>1803.330</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12331.272</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 30 30 20</th>\n",
       "      <td>17762.046</td>\n",
       "      <td>1822.661</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.013</td>\n",
       "      <td>12227.814</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>17762.046</td>\n",
       "      <td>1822.661</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.013</td>\n",
       "      <td>12227.814</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 50 10 10</th>\n",
       "      <td>17762.046</td>\n",
       "      <td>1822.661</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.013</td>\n",
       "      <td>12227.814</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>18429.855</td>\n",
       "      <td>2328.360</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.018</td>\n",
       "      <td>12353.008</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 50 10 10</th>\n",
       "      <td>17802.636</td>\n",
       "      <td>2221.436</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12344.916</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 20 40</th>\n",
       "      <td>18610.175</td>\n",
       "      <td>2260.916</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.017</td>\n",
       "      <td>12465.021</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 30 10</th>\n",
       "      <td>18610.175</td>\n",
       "      <td>2260.916</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.017</td>\n",
       "      <td>12465.021</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 30 10</th>\n",
       "      <td>17408.697</td>\n",
       "      <td>1613.442</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12153.772</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 26 27 27 20</th>\n",
       "      <td>17408.697</td>\n",
       "      <td>1613.442</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12153.772</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 26 27 27 20</th>\n",
       "      <td>17683.220</td>\n",
       "      <td>1722.557</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12234.719</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 23 24 24 30</th>\n",
       "      <td>18189.306</td>\n",
       "      <td>1991.202</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.015</td>\n",
       "      <td>12380.729</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Test RMSE        SE  Jack R2  \\\n",
       "Forward                                    23834.417  4933.468    0.884   \n",
       "GBoost                                     19401.538  2816.862    0.923   \n",
       "AdaBoost                                   26290.713  3510.404    0.859   \n",
       "XGBoost                                    20400.397  3406.287    0.915   \n",
       "XGBoost, ada, GB                           20358.669  3513.519    0.915   \n",
       "xg GB                                      19250.267  3211.549    0.924   \n",
       "xg adaboost                                21745.027  3713.139    0.903   \n",
       "Random Forest                              25875.535  3534.220    0.863   \n",
       "XGBoost, random tree, GB                   20268.412  3515.703    0.916   \n",
       "xg Random tree                             21605.204  3717.447    0.905   \n",
       "XGBoost, GBoost Random Forest              20268.412  3515.703    0.916   \n",
       "LASSO                                      34657.818  7340.865    0.755   \n",
       "Ridge alpha 10                             23016.283  6348.168    0.892   \n",
       "XGBoost, GBoost Random Forest Ridge        18023.909  2135.523    0.934   \n",
       "XGBoost, GBoost Random Forest LASSO        20548.107  2930.692    0.914   \n",
       "ENET                                       34151.039  8005.147    0.762   \n",
       "XGBoost, GBoost Random Forest ENET         20399.404  2913.771    0.915   \n",
       "XGBoost, GBoost Ridge                      17281.535  1636.619    0.939   \n",
       "XGBoost, GBoost Ridge Forward              17862.469  1812.492    0.935   \n",
       "XGBoost, GBoost Ridge Forward Tree         17883.572  1748.030    0.935   \n",
       "XGBoost, GBoost Ridge Forward Lasso        19715.427  2888.109    0.921   \n",
       "XGBoost, GBoost, RandomTree                20268.412  3515.703    0.916   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  17571.955  1657.378    0.937   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  17862.755  2279.217    0.935   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  18429.855  2328.360    0.931   \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15  17572.052  1869.569    0.937   \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20  17545.527  1643.278    0.937   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  17533.736  1628.856    0.937   \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30  17935.120  1803.330    0.934   \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20  17762.046  1822.661    0.936   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  17762.046  1822.661    0.936   \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  17762.046  1822.661    0.936   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  18429.855  2328.360    0.931   \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  17802.636  2221.436    0.935   \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40  18610.175  2260.916    0.929   \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  18610.175  2260.916    0.929   \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  17408.697  1613.442    0.938   \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  17408.697  1613.442    0.938   \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  17683.220  1722.557    0.936   \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30  18189.306  1991.202    0.932   \n",
       "\n",
       "                                              SE        MAE  R-square  \n",
       "Forward                                    0.047  14042.658     0.884  \n",
       "GBoost                                     0.015  12968.305     0.923  \n",
       "AdaBoost                                   0.023  18384.608     0.859  \n",
       "XGBoost                                    0.020  13619.232     0.915  \n",
       "XGBoost, ada, GB                           0.020  13512.210     0.915  \n",
       "xg GB                                      0.017  12745.760     0.924  \n",
       "xg adaboost                                0.023  14624.200     0.903  \n",
       "Random Forest                              0.023  18050.721     0.863  \n",
       "XGBoost, random tree, GB                   0.020  13428.969     0.916  \n",
       "xg Random tree                             0.022  14536.721     0.905  \n",
       "XGBoost, GBoost Random Forest              0.020  13428.969     0.916  \n",
       "LASSO                                      0.097  20087.645     0.755  \n",
       "Ridge alpha 10                             0.055  12901.650     0.892  \n",
       "XGBoost, GBoost Random Forest Ridge        0.010  12574.029     0.934  \n",
       "XGBoost, GBoost Random Forest LASSO        0.016  13845.466     0.914  \n",
       "ENET                                       0.103  18888.261     0.762  \n",
       "XGBoost, GBoost Random Forest ENET         0.016  13711.384     0.915  \n",
       "XGBoost, GBoost Ridge                      0.008  12111.831     0.939  \n",
       "XGBoost, GBoost Ridge Forward              0.012  12284.778     0.935  \n",
       "XGBoost, GBoost Ridge Forward Tree         0.009  12535.058     0.935  \n",
       "XGBoost, GBoost Ridge Forward Lasso        0.022  12719.451     0.921  \n",
       "XGBoost, GBoost, RandomTree                0.020  13428.969     0.916  \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  0.009  12249.831     0.937  \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  0.011  12360.641     0.935  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.018  12353.008     0.931  \n",
       "XGBoost, GBoost Ridge Forward 35 35 15 15  0.009  12275.339     0.937  \n",
       "XGBoost, GBoost Ridge Forward 25 35 20 20  0.009  12248.799     0.937  \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  0.009  12260.901     0.937  \n",
       "XGBoost, GBoost Ridge Forward 20 30 20 30  0.012  12331.272     0.934  \n",
       "XGBoost, GBoost Ridge Forward 20 30 30 20  0.013  12227.814     0.936  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.013  12227.814     0.936  \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  0.013  12227.814     0.936  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.018  12353.008     0.931  \n",
       "XGBoost, GBoost Ridge Forward 30 50 10 10  0.010  12344.916     0.935  \n",
       "XGBoost, GBoost Ridge Forward 20 20 20 40  0.017  12465.021     0.929  \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  0.017  12465.021     0.929  \n",
       "XGBoost, GBoost Ridge Forward 30 30 30 10  0.009  12153.772     0.938  \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  0.009  12153.772     0.938  \n",
       "XGBoost, GBoost Ridge Forward 26 27 27 20  0.011  12234.719     0.936  \n",
       "XGBoost, GBoost Ridge Forward 23 24 24 30  0.015  12380.729     0.932  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResultTable(rows, predictions):\n",
    "    columns=['Test RMSE', 'SE', 'Jack R2', 'SE', 'MAE', 'R-square']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        results.iloc[row,0], results.iloc[row,1] = rmse_jack(y_test, pred)\n",
    "        results.iloc[row,2], results.iloc[row,3] = (r2_jack(y_test, pred))\n",
    "        results.iloc[row,4] = mean_absolute_error(y_test, pred)\n",
    "        results.iloc[row,5] = r2_score(y_test,pred)\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction1 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction1.to_csv(\"Day9_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = (np.exp(predFinalBoost)+np.exp(prediction)+np.exp(y_pred_rg)+np.exp(predforward))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction2 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction2.to_csv(\"Day9_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)\n",
    "xgdmat = xgb.DMatrix(data, y_price) # Create our DMatrix to make XGBoost more efficient\n",
    "testFinaldmat = xgb.DMatrix(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "prediction = final_gb.predict(testFinaldmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(data,y_price)\n",
    "predFinalBoost = GBoost.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(data, y_price)\n",
    "y_pred_rg = (rg.predict(kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(data, y_price)\n",
    "predforward = fwd.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = ((0.3*np.exp(prediction))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction3 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction3.to_csv(\"Day9_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = ((0.2*np.exp(prediction))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction4 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction4.to_csv(\"Day9_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = ((0.3*np.exp(prediction))+(0.3*np.exp(predFinalBoost))+(0.3*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction4 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction4.to_csv(\"Day9_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
