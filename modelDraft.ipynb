{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "data = pd.read_csv('train2.csv')\n",
    "\n",
    "\n",
    "#y_train = final_train.pop('LogPrice')\n",
    "#y_test = final_test.pop('LogPrice')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = ['SalePrice']\n",
    "\n",
    "predictors=[x for x in list(data.columns) if x not in response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train = data.sample(frac=0.3, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "\n",
    "mu=final_train[predictors].mean()\n",
    "sigma=final_train[predictors].std()\n",
    "\n",
    "final_train[predictors]=(final_train[predictors]-mu)/sigma\n",
    "final_test[predictors]=(final_test[predictors]-mu)/sigma\n",
    "\n",
    "#y_train = final_train.pop('BoxCoxPrice')\n",
    "#y_test = final_test.pop('BoxCoxPrice')\n",
    "\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-661d7b57ff21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yiran/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiran/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0;32m--> 111\u001b[0;31m                          y_numeric=is_regressor(self))\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiran/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/yiran/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yiran/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor\n",
    "#http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_regression.html\n",
    "\n",
    "regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=9),random_state=0)\n",
    "regr.fit(final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#This uses cross validation to evaluate the score\n",
    "cross_val_score(regr, final_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "values = range(1,20)\n",
    "maximum = 0\n",
    "optimal_node = 0\n",
    "for i in values:\n",
    "    regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=i),random_state=0)\n",
    "    print(\"Cross val score for {} nodes\".format(i))\n",
    "    print(cross_val_score(regr, final_train, y_train, cv=10))\n",
    "    tot = 0\n",
    "    g = cross_val_score(regr, final_train, y_train, cv=10)\n",
    "    #Check to see if this layer is better since highest cross_val_score\n",
    "    for x in g:\n",
    "        tot = tot+x\n",
    "    if tot>maximum:\n",
    "        optimal_node = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"Optimal nodes is {}\".format(19))\n",
    "regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=19),random_state=0)\n",
    "print(\"Cross val score for {} nodes\".format(19))\n",
    "print(cross_val_score(regr, final_train, y_train, cv=10))\n",
    "\n",
    "regr.fit(final_train, y_train)\n",
    "y_1 = regr.predict(final_test)\n",
    "accuracy = r2_score(y_test, y_1)\n",
    "print(\"Cross-Predicted Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "#Jackknife method to be able to report the standard errors for the test results\n",
    "\n",
    "columns=['Test RMSE', 'SE', 'Test R2', 'SE']\n",
    "rows = ['Results']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "results.iloc[0,0], results.iloc[0,1] = rmse_jack(y_test, y_1)\n",
    "results.iloc[0,2], results.iloc[0,3] = (r2_jack(y_test, y_1))\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = LassoCV(cv=10)\n",
    "lasso.fit(final_train, np.ravel(y_train)) \n",
    "pred_L = lasso.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The decision tree with AdaBoosting\n",
    "regr.fit(final_train, y_train)\n",
    "pred_T = regr.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining the 2 predictions\n",
    "pred_combined = (pred_L+pred_T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Test RMSE', 'SE', 'Test R2', 'SE']\n",
    "rows = ['Lasso', 'Adaboost Tree', 'Lasso + Tree']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "results.iloc[0,0], results.iloc[0,1] = rmse_jack(y_test, pred_L)\n",
    "results.iloc[0,2], results.iloc[0,3] = (r2_jack(y_test, pred_L))\n",
    "results.iloc[1,0], results.iloc[1,1] = rmse_jack(y_test, pred_T)\n",
    "results.iloc[1,2], results.iloc[1,3] = (r2_jack(y_test, pred_T))\n",
    "results.iloc[2,0], results.iloc[2,1] = rmse_jack(y_test, pred_combined)\n",
    "results.iloc[2,2], results.iloc[2,3] = (r2_jack(y_test, pred_combined))\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "enet = ElasticNetCV(l1_ratio=[0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99], cv=5)\n",
    "enet.fit(final_train, np.ravel(y_train))\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=enet.alpha_, l1_ratio=enet.l1_ratio_)\n",
    "enet.fit(final_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alphas = np.exp(np.linspace(-10,20,500)) \n",
    "ridge = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge.fit(final_train, np.ravel(y_train))\n",
    "ridge = Ridge(alpha=ridge.alpha_)\n",
    "ridge.fit(final_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_R = ridge.predict(final_test)\n",
    "pred_L = lasso.predict(final_test)\n",
    "pred_E = enet.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining the all predictions\n",
    "pred_combined = (pred_L+pred_T)/2\n",
    "pred_combined2 = (pred_R+pred_T)/2\n",
    "pred_combined3 = (pred_E+pred_T)/2\n",
    "pred_combined4 = (pred_L+ + pred_R + pred_E + pred_T)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Test RMSE', 'SE', 'Test R2', 'SE']\n",
    "rows = ['Lasso', 'Adaboost Tree', 'Lasso + Tree', 'Ridge', 'Enet', 'Tree + Ridge', 'Tree + Enet', 'Tree + All 3']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "results.iloc[0,0], results.iloc[0,1] = rmse_jack(y_test, pred_L)\n",
    "results.iloc[0,2], results.iloc[0,3] = (r2_jack(y_test, pred_L))\n",
    "results.iloc[1,0], results.iloc[1,1] = rmse_jack(y_test, pred_T)\n",
    "results.iloc[1,2], results.iloc[1,3] = (r2_jack(y_test, pred_T))\n",
    "results.iloc[2,0], results.iloc[2,1] = rmse_jack(y_test, pred_combined)\n",
    "results.iloc[2,2], results.iloc[2,3] = (r2_jack(y_test, pred_combined))\n",
    "results.iloc[3,0], results.iloc[3,1] = rmse_jack(y_test, pred_R)\n",
    "results.iloc[3,2], results.iloc[3,3] = (r2_jack(y_test, pred_R))\n",
    "results.iloc[4,0], results.iloc[4,1] = rmse_jack(y_test, pred_E)\n",
    "results.iloc[4,2], results.iloc[4,3] = (r2_jack(y_test, pred_E))\n",
    "results.iloc[5,0], results.iloc[5,1] = rmse_jack(y_test, pred_combined2)\n",
    "results.iloc[5,2], results.iloc[5,3] = (r2_jack(y_test, pred_combined2))\n",
    "results.iloc[6,0], results.iloc[6,1] = rmse_jack(y_test, pred_combined3)\n",
    "results.iloc[6,2], results.iloc[6,3] = (r2_jack(y_test, pred_combined3))\n",
    "results.iloc[7,0], results.iloc[7,1] = rmse_jack(y_test, pred_combined4)\n",
    "results.iloc[7,2], results.iloc[7,3] = (r2_jack(y_test, pred_combined4))\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
