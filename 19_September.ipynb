{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from QBUS2820 import rmse_jack, r2_jack \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from ExtraCode import getResultTable\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from QBUS2820 import forward\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from QBUS2820 import pcrCV\n",
    "from QBUS2820 import plsCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037147231456744451"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LotArea'].corr(data['LotFrontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "method = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward selection\n",
    "fwd = forward()\n",
    "fwd.fit(final_train, y_train)\n",
    "predforward = fwd.predict(final_test)\n",
    "method.append('Forward')\n",
    "pred.append(np.exp(predforward))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "GBoost.fit(final_train,y_train)\n",
    "predFinalBoost = GBoost.predict(final_test)\n",
    "method.append('GBoost')\n",
    "pred.append(np.exp(predFinalBoost))\n",
    "\n",
    "regr = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "regr = regr.fit(final_train,y_train)\n",
    "adapred = regr.predict(final_test)\n",
    "method.append('AdaBoost')\n",
    "pred.append(np.exp(adapred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(final_train, y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear', 'max_depth':3, 'min_child_weight':1} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 432)\n",
    "testFinaldmat = xgb.DMatrix(final_test)\n",
    "xgpred = final_gb.predict(testFinaldmat)\n",
    "method.append('XGBoost')\n",
    "pred.append(np.exp(xgpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = (np.exp(xgpred)+np.exp(adapred)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred2)\n",
    "method.append('XGBoost, ada, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = (np.exp(xgpred)+np.exp(predFinalBoost))/2\n",
    "\n",
    "pred5 = (np.exp(xgpred)+np.exp(adapred))/2\n",
    "pred.append(pred3)\n",
    "pred.append(pred5)\n",
    "method.append('xg GB')\n",
    "method.append('xg adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extremely Random forest\n",
    "regr2 = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "regr2 = regr.fit(final_train,y_train)\n",
    "\n",
    "predFinalExtRandomForestlad = regr2.predict(final_test)\n",
    "pred.append(np.exp(predFinalExtRandomForestlad))\n",
    "method.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred5 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad)+np.exp(predFinalBoost))/3\n",
    "pred.append(pred5)\n",
    "method.append('XGBoost, random tree, GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred6 = (np.exp(xgpred)+np.exp(predFinalExtRandomForestlad))/2\n",
    "pred.append(pred6)\n",
    "method.append('xg Random tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred10 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred10)\n",
    "method.append('XGBoost, GBoost Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LASSO\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(final_train, np.ravel(y_train)) \n",
    "pred_L = lasso.predict(final_test)\n",
    "method.append('LASSO')\n",
    "pred.append(np.exp(pred_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "rg = Ridge(alpha = alpha)\n",
    "rg.fit(final_train, y_train)\n",
    "y_pred_rg = (rg.predict(final_test))\n",
    "y_pred_rg\n",
    "\n",
    "pred.append(np.exp(y_pred_rg))\n",
    "method.append('Ridge alpha 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred11 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(y_pred_rg))/4\n",
    "pred.append(pred11)\n",
    "method.append('XGBoost, GBoost Random Forest Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred_L))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = ElasticNet(random_state=0, alpha = 1)\n",
    "    \n",
    "regr.fit(final_train, y_train)    \n",
    "pred13 = regr.predict(final_test)\n",
    "pred.append(np.exp(pred13))\n",
    "method.append('ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred12 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(predFinalExtRandomForestlad)+np.exp(pred13))/4\n",
    "pred.append(pred12)\n",
    "method.append('XGBoost, GBoost Random Forest ENET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred13 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg))/3\n",
    "pred.append(pred13)\n",
    "method.append('XGBoost, GBoost Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred14 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward))/4\n",
    "pred.append(pred14)\n",
    "method.append('XGBoost, GBoost Ridge Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(predFinalExtRandomForestlad))/5\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = (np.exp(xgpred)+np.exp(predFinalBoost)+np.exp(y_pred_rg)+np.exp(predforward)+ np.exp(pred_L))/5\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred15 = (np.exp(xgpred)+np.exp(predFinalBoost)+ np.exp(predFinalExtRandomForestlad))/3\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost, RandomTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred15 = ((0.3*np.exp(xgpred))+(0.3*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred15)\n",
    "method.append('XGBoost, GBoost Ridge Forward 30 30 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred16 = ((0.4*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.1*np.exp(predforward)))\n",
    "pred.append(pred16)\n",
    "method.append('XGBoost, GBoost Ridge Forward 40 40 10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred20 = ((0.2*np.exp(xgpred))+(0.4*np.exp(predFinalBoost))+(0.2*np.exp(y_pred_rg))+(0.2*np.exp(predforward)))\n",
    "pred.append(pred20)\n",
    "method.append('XGBoost, GBoost Ridge Forward 20 40 20 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred21 = ((0.15*np.exp(xgpred))+(0.35*np.exp(predFinalBoost))+(0.1*np.exp(y_pred_rg))+(0.35*np.exp(predforward))+ (0.05*np.exp(predFinalExtRandomForestlad)))\n",
    "pred.append(pred21)\n",
    "method.append('XGBoost, GBoost Ridge Forward RandomForest 15 35 10 35 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import table\n",
    "def getResultTable(rows, predictions):\n",
    "    columns=['Test RMSE', 'SE', 'Jack R2', 'SE', 'MAE', 'R-square']\n",
    "    results=pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "    for row,pred in zip(range(0,len(rows)),predictions):\n",
    "        results.iloc[row,0], results.iloc[row,1] = rmse_jack(y_test, pred)\n",
    "        results.iloc[row,2], results.iloc[row,3] = (r2_jack(y_test, pred))\n",
    "        results.iloc[row,4] = mean_absolute_error(y_test, pred)\n",
    "        results.iloc[row,5] = r2_score(y_test,pred)\n",
    "        \n",
    "    ax = plt.subplot(111, frame_on=False) # no visible frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    table(ax, results)  \n",
    "    plt.savefig('ResultTable.png')\n",
    "    return results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>23834.417</td>\n",
       "      <td>4933.468</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.047</td>\n",
       "      <td>14042.658</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>19401.538</td>\n",
       "      <td>2816.862</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.015</td>\n",
       "      <td>12968.305</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>26103.400</td>\n",
       "      <td>3564.944</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.024</td>\n",
       "      <td>18208.122</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>20400.397</td>\n",
       "      <td>3406.287</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13619.232</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>20346.542</td>\n",
       "      <td>3526.990</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13489.676</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>19250.267</td>\n",
       "      <td>3211.549</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.017</td>\n",
       "      <td>12745.760</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>21708.301</td>\n",
       "      <td>3736.986</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.023</td>\n",
       "      <td>14576.759</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>25833.711</td>\n",
       "      <td>3558.376</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.024</td>\n",
       "      <td>18034.141</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>20305.248</td>\n",
       "      <td>3519.203</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13478.282</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>21641.797</td>\n",
       "      <td>3725.503</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.023</td>\n",
       "      <td>14591.754</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>20305.248</td>\n",
       "      <td>3519.203</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13478.282</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>34657.818</td>\n",
       "      <td>7340.865</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.097</td>\n",
       "      <td>20087.645</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>23016.283</td>\n",
       "      <td>6348.168</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12901.650</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>18058.687</td>\n",
       "      <td>2136.968</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12603.529</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>20580.466</td>\n",
       "      <td>2933.107</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13870.926</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>34151.039</td>\n",
       "      <td>8005.147</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.103</td>\n",
       "      <td>18888.261</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>20428.631</td>\n",
       "      <td>2916.578</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.016</td>\n",
       "      <td>13727.252</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>17281.535</td>\n",
       "      <td>1636.619</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12111.831</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>17862.469</td>\n",
       "      <td>1812.492</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12284.778</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>17911.231</td>\n",
       "      <td>1751.788</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12568.346</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Lasso</th>\n",
       "      <td>19715.427</td>\n",
       "      <td>2888.109</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.022</td>\n",
       "      <td>12719.451</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost, RandomTree</th>\n",
       "      <td>20305.248</td>\n",
       "      <td>3519.203</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.020</td>\n",
       "      <td>13478.282</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 20 20</th>\n",
       "      <td>17571.955</td>\n",
       "      <td>1657.378</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12249.831</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 40 40 10 10</th>\n",
       "      <td>17862.755</td>\n",
       "      <td>2279.217</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.011</td>\n",
       "      <td>12360.641</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 40 20 20</th>\n",
       "      <td>17533.736</td>\n",
       "      <td>1628.856</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12260.901</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward RandomForest 15 35 10 35 5</th>\n",
       "      <td>17943.366</td>\n",
       "      <td>1706.644</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12430.518</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Test RMSE        SE  \\\n",
       "Forward                                             23834.417  4933.468   \n",
       "GBoost                                              19401.538  2816.862   \n",
       "AdaBoost                                            26103.400  3564.944   \n",
       "XGBoost                                             20400.397  3406.287   \n",
       "XGBoost, ada, GB                                    20346.542  3526.990   \n",
       "xg GB                                               19250.267  3211.549   \n",
       "xg adaboost                                         21708.301  3736.986   \n",
       "Random Forest                                       25833.711  3558.376   \n",
       "XGBoost, random tree, GB                            20305.248  3519.203   \n",
       "xg Random tree                                      21641.797  3725.503   \n",
       "XGBoost, GBoost Random Forest                       20305.248  3519.203   \n",
       "LASSO                                               34657.818  7340.865   \n",
       "Ridge alpha 10                                      23016.283  6348.168   \n",
       "XGBoost, GBoost Random Forest Ridge                 18058.687  2136.968   \n",
       "XGBoost, GBoost Random Forest LASSO                 20580.466  2933.107   \n",
       "ENET                                                34151.039  8005.147   \n",
       "XGBoost, GBoost Random Forest ENET                  20428.631  2916.578   \n",
       "XGBoost, GBoost Ridge                               17281.535  1636.619   \n",
       "XGBoost, GBoost Ridge Forward                       17862.469  1812.492   \n",
       "XGBoost, GBoost Ridge Forward Tree                  17911.231  1751.788   \n",
       "XGBoost, GBoost Ridge Forward Lasso                 19715.427  2888.109   \n",
       "XGBoost, GBoost, RandomTree                         20305.248  3519.203   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20           17571.955  1657.378   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10           17862.755  2279.217   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20           17533.736  1628.856   \n",
       "XGBoost, GBoost Ridge Forward RandomForest 15 3...  17943.366  1706.644   \n",
       "\n",
       "                                                    Jack R2     SE        MAE  \\\n",
       "Forward                                               0.884  0.047  14042.658   \n",
       "GBoost                                                0.923  0.015  12968.305   \n",
       "AdaBoost                                              0.861  0.024  18208.122   \n",
       "XGBoost                                               0.915  0.020  13619.232   \n",
       "XGBoost, ada, GB                                      0.915  0.020  13489.676   \n",
       "xg GB                                                 0.924  0.017  12745.760   \n",
       "xg adaboost                                           0.904  0.023  14576.759   \n",
       "Random Forest                                         0.864  0.024  18034.141   \n",
       "XGBoost, random tree, GB                              0.916  0.020  13478.282   \n",
       "xg Random tree                                        0.904  0.023  14591.754   \n",
       "XGBoost, GBoost Random Forest                         0.916  0.020  13478.282   \n",
       "LASSO                                                 0.755  0.097  20087.645   \n",
       "Ridge alpha 10                                        0.892  0.055  12901.650   \n",
       "XGBoost, GBoost Random Forest Ridge                   0.933  0.010  12603.529   \n",
       "XGBoost, GBoost Random Forest LASSO                   0.913  0.016  13870.926   \n",
       "ENET                                                  0.762  0.103  18888.261   \n",
       "XGBoost, GBoost Random Forest ENET                    0.915  0.016  13727.252   \n",
       "XGBoost, GBoost Ridge                                 0.939  0.008  12111.831   \n",
       "XGBoost, GBoost Ridge Forward                         0.935  0.012  12284.778   \n",
       "XGBoost, GBoost Ridge Forward Tree                    0.934  0.009  12568.346   \n",
       "XGBoost, GBoost Ridge Forward Lasso                   0.921  0.022  12719.451   \n",
       "XGBoost, GBoost, RandomTree                           0.916  0.020  13478.282   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20             0.937  0.009  12249.831   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10             0.935  0.011  12360.641   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20             0.937  0.009  12260.901   \n",
       "XGBoost, GBoost Ridge Forward RandomForest 15 3...    0.934  0.010  12430.518   \n",
       "\n",
       "                                                    R-square  \n",
       "Forward                                                0.884  \n",
       "GBoost                                                 0.923  \n",
       "AdaBoost                                               0.861  \n",
       "XGBoost                                                0.915  \n",
       "XGBoost, ada, GB                                       0.915  \n",
       "xg GB                                                  0.924  \n",
       "xg adaboost                                            0.904  \n",
       "Random Forest                                          0.864  \n",
       "XGBoost, random tree, GB                               0.916  \n",
       "xg Random tree                                         0.904  \n",
       "XGBoost, GBoost Random Forest                          0.916  \n",
       "LASSO                                                  0.755  \n",
       "Ridge alpha 10                                         0.892  \n",
       "XGBoost, GBoost Random Forest Ridge                    0.933  \n",
       "XGBoost, GBoost Random Forest LASSO                    0.913  \n",
       "ENET                                                   0.762  \n",
       "XGBoost, GBoost Random Forest ENET                     0.915  \n",
       "XGBoost, GBoost Ridge                                  0.939  \n",
       "XGBoost, GBoost Ridge Forward                          0.935  \n",
       "XGBoost, GBoost Ridge Forward Tree                     0.934  \n",
       "XGBoost, GBoost Ridge Forward Lasso                    0.921  \n",
       "XGBoost, GBoost, RandomTree                            0.916  \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20              0.937  \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10              0.935  \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20              0.937  \n",
       "XGBoost, GBoost Ridge Forward RandomForest 15 3...     0.934  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heating_Grav</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd_AsphShn</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation_Stone</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_Feedr</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heating_OthW</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heating_Floor</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1_PosA</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st_ImStucc</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1_RRNn</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_PosN</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st_BrkComm</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_Artery</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heating_Wall</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>21.886116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>15.719250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd_Stone</th>\n",
       "      <td>15.427384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical_FuseP</th>\n",
       "      <td>15.427384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd_ImStucc</th>\n",
       "      <td>15.427384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1_RRNe</th>\n",
       "      <td>15.427384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd_Brk Cmn</th>\n",
       "      <td>12.556788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_Blmngtn</th>\n",
       "      <td>12.556788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotConfig_FR3</th>\n",
       "      <td>12.556788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType_BrkCmn</th>\n",
       "      <td>12.556788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>11.490177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldgType_2fmCon</th>\n",
       "      <td>10.840128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <td>10.840128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <td>10.840128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_NPkVill</th>\n",
       "      <td>10.840128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>9.970021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1_RRAn</th>\n",
       "      <td>9.664910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemod/Add</th>\n",
       "      <td>-0.332967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <td>-0.362666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>-0.417940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType_None</th>\n",
       "      <td>-0.541656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape</th>\n",
       "      <td>-0.609901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenQual</th>\n",
       "      <td>-0.673121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>-0.780394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotConfig_Inside</th>\n",
       "      <td>-0.945472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>-0.981845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <td>-1.337911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>-1.354528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofStyle_Gable</th>\n",
       "      <td>-1.625483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldgType_1Fam</th>\n",
       "      <td>-1.736447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual</th>\n",
       "      <td>-1.980665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1_Norm</th>\n",
       "      <td>-2.112270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterCond</th>\n",
       "      <td>-2.566171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical_SBrkr</th>\n",
       "      <td>-2.636266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour_Lvl</th>\n",
       "      <td>-2.674372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>-2.807420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>-3.132471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PavedDrive</th>\n",
       "      <td>-3.227895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>-3.469179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CentralAir</th>\n",
       "      <td>-3.552059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>-3.857448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>-3.994337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType_WD</th>\n",
       "      <td>-4.471905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heating_GasA</th>\n",
       "      <td>-7.567488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_CompShg</th>\n",
       "      <td>-7.567488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_Norm</th>\n",
       "      <td>-12.556788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>-15.427384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Skew\n",
       "Heating_Grav          21.886116\n",
       "Exterior2nd_AsphShn   21.886116\n",
       "Foundation_Stone      21.886116\n",
       "Condition2_Feedr      21.886116\n",
       "Heating_OthW          21.886116\n",
       "Heating_Floor         21.886116\n",
       "Condition1_PosA       21.886116\n",
       "Exterior1st_ImStucc   21.886116\n",
       "Condition1_RRNn       21.886116\n",
       "Condition2_PosN       21.886116\n",
       "Exterior1st_BrkComm   21.886116\n",
       "Condition2_Artery     21.886116\n",
       "Heating_Wall          21.886116\n",
       "PoolArea              21.886116\n",
       "MiscVal               15.719250\n",
       "Exterior2nd_Stone     15.427384\n",
       "Electrical_FuseP      15.427384\n",
       "Exterior2nd_ImStucc   15.427384\n",
       "Condition1_RRNe       15.427384\n",
       "Exterior2nd_Brk Cmn   12.556788\n",
       "Neighborhood_Blmngtn  12.556788\n",
       "LotConfig_FR3         12.556788\n",
       "MasVnrType_BrkCmn     12.556788\n",
       "LowQualFinSF          11.490177\n",
       "BldgType_2fmCon       10.840128\n",
       "HouseStyle_2.5Unf     10.840128\n",
       "HouseStyle_1.5Unf     10.840128\n",
       "Neighborhood_NPkVill  10.840128\n",
       "3SsnPorch              9.970021\n",
       "Condition1_RRAn        9.664910\n",
       "...                         ...\n",
       "YearRemod/Add         -0.332967\n",
       "GarageType_Attchd     -0.362666\n",
       "YearBuilt             -0.417940\n",
       "MasVnrType_None       -0.541656\n",
       "LotShape              -0.609901\n",
       "KitchenQual           -0.673121\n",
       "MoSold                -0.780394\n",
       "LotConfig_Inside      -0.945472\n",
       "Alley                 -0.981845\n",
       "MSZoning_RL           -1.337911\n",
       "BsmtExposure          -1.354528\n",
       "RoofStyle_Gable       -1.625483\n",
       "BldgType_1Fam         -1.736447\n",
       "ExterQual             -1.980665\n",
       "Condition1_Norm       -2.112270\n",
       "ExterCond             -2.566171\n",
       "Electrical_SBrkr      -2.636266\n",
       "LandContour_Lvl       -2.674372\n",
       "BsmtFinType2          -2.807420\n",
       "GarageQual            -3.132471\n",
       "PavedDrive            -3.227895\n",
       "BsmtCond              -3.469179\n",
       "CentralAir            -3.552059\n",
       "GarageCond            -3.857448\n",
       "Functional            -3.994337\n",
       "SaleType_WD           -4.471905\n",
       "Heating_GasA          -7.567488\n",
       "RoofMatl_CompShg      -7.567488\n",
       "Condition2_Norm      -12.556788\n",
       "Street               -15.427384\n",
       "\n",
       "[178 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "\n",
    "numeric_feats = final_train.dtypes[final_train.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = final_train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness\n",
    "\n",
    "#Looking at skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 178 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_5.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>SE</th>\n",
       "      <th>Jack R2</th>\n",
       "      <th>SE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>23834.417</td>\n",
       "      <td>4933.468</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.047</td>\n",
       "      <td>14042.658</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>19848.273</td>\n",
       "      <td>2726.571</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.014</td>\n",
       "      <td>13377.121</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>25888.656</td>\n",
       "      <td>3485.843</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.023</td>\n",
       "      <td>18085.040</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>21585.497</td>\n",
       "      <td>3938.374</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.024</td>\n",
       "      <td>13920.576</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, ada, GB</th>\n",
       "      <td>20694.955</td>\n",
       "      <td>3654.334</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.021</td>\n",
       "      <td>13727.146</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg GB</th>\n",
       "      <td>20062.619</td>\n",
       "      <td>3413.365</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.019</td>\n",
       "      <td>13108.635</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg adaboost</th>\n",
       "      <td>22081.719</td>\n",
       "      <td>3984.074</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.025</td>\n",
       "      <td>14591.918</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>26084.902</td>\n",
       "      <td>3501.659</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.023</td>\n",
       "      <td>18270.072</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, random tree, GB</th>\n",
       "      <td>20745.481</td>\n",
       "      <td>3662.208</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.021</td>\n",
       "      <td>13763.250</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg Random tree</th>\n",
       "      <td>22174.749</td>\n",
       "      <td>3991.683</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.025</td>\n",
       "      <td>14670.214</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest</th>\n",
       "      <td>20745.481</td>\n",
       "      <td>3662.208</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.021</td>\n",
       "      <td>13763.250</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>34657.818</td>\n",
       "      <td>7340.865</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.097</td>\n",
       "      <td>20087.645</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge alpha 10</th>\n",
       "      <td>23010.459</td>\n",
       "      <td>6348.543</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12898.336</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest Ridge</th>\n",
       "      <td>18497.501</td>\n",
       "      <td>2219.194</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12891.733</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest LASSO</th>\n",
       "      <td>21063.308</td>\n",
       "      <td>3010.616</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.017</td>\n",
       "      <td>14171.517</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>34151.039</td>\n",
       "      <td>8005.147</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.103</td>\n",
       "      <td>18888.261</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Random Forest ENET</th>\n",
       "      <td>20916.213</td>\n",
       "      <td>2994.910</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.017</td>\n",
       "      <td>14041.033</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge</th>\n",
       "      <td>17929.599</td>\n",
       "      <td>1742.006</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12451.361</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward</th>\n",
       "      <td>18373.520</td>\n",
       "      <td>1864.155</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.013</td>\n",
       "      <td>12531.320</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Tree</th>\n",
       "      <td>18320.203</td>\n",
       "      <td>1815.595</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12802.761</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward Lasso</th>\n",
       "      <td>20134.704</td>\n",
       "      <td>2907.016</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.022</td>\n",
       "      <td>12929.549</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost, RandomTree</th>\n",
       "      <td>20745.481</td>\n",
       "      <td>3662.208</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.021</td>\n",
       "      <td>13763.250</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 30 30 20 20</th>\n",
       "      <td>18176.651</td>\n",
       "      <td>1744.925</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12553.611</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 40 40 10 10</th>\n",
       "      <td>18608.320</td>\n",
       "      <td>2417.554</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.012</td>\n",
       "      <td>12742.443</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 20 30 30</th>\n",
       "      <td>18838.043</td>\n",
       "      <td>2349.639</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.018</td>\n",
       "      <td>12563.029</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost, GBoost Ridge Forward 20 40 20 20</th>\n",
       "      <td>18027.990</td>\n",
       "      <td>1672.421</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.009</td>\n",
       "      <td>12521.543</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Test RMSE        SE  Jack R2  \\\n",
       "Forward                                    23834.417  4933.468    0.884   \n",
       "GBoost                                     19848.273  2726.571    0.919   \n",
       "AdaBoost                                   25888.656  3485.843    0.863   \n",
       "XGBoost                                    21585.497  3938.374    0.905   \n",
       "XGBoost, ada, GB                           20694.955  3654.334    0.912   \n",
       "xg GB                                      20062.619  3413.365    0.918   \n",
       "xg adaboost                                22081.719  3984.074    0.900   \n",
       "Random Forest                              26084.902  3501.659    0.861   \n",
       "XGBoost, random tree, GB                   20745.481  3662.208    0.912   \n",
       "xg Random tree                             22174.749  3991.683    0.900   \n",
       "XGBoost, GBoost Random Forest              20745.481  3662.208    0.912   \n",
       "LASSO                                      34657.818  7340.865    0.755   \n",
       "Ridge alpha 10                             23010.459  6348.543    0.892   \n",
       "XGBoost, GBoost Random Forest Ridge        18497.501  2219.194    0.930   \n",
       "XGBoost, GBoost Random Forest LASSO        21063.308  3010.616    0.909   \n",
       "ENET                                       34151.039  8005.147    0.762   \n",
       "XGBoost, GBoost Random Forest ENET         20916.213  2994.910    0.911   \n",
       "XGBoost, GBoost Ridge                      17929.599  1742.006    0.934   \n",
       "XGBoost, GBoost Ridge Forward              18373.520  1864.155    0.931   \n",
       "XGBoost, GBoost Ridge Forward Tree         18320.203  1815.595    0.931   \n",
       "XGBoost, GBoost Ridge Forward Lasso        20134.704  2907.016    0.917   \n",
       "XGBoost, GBoost, RandomTree                20745.481  3662.208    0.912   \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  18176.651  1744.925    0.932   \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  18608.320  2417.554    0.929   \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  18838.043  2349.639    0.927   \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  18027.990  1672.421    0.934   \n",
       "\n",
       "                                              SE        MAE  R-square  \n",
       "Forward                                    0.047  14042.658     0.884  \n",
       "GBoost                                     0.014  13377.121     0.919  \n",
       "AdaBoost                                   0.023  18085.040     0.863  \n",
       "XGBoost                                    0.024  13920.576     0.905  \n",
       "XGBoost, ada, GB                           0.021  13727.146     0.912  \n",
       "xg GB                                      0.019  13108.635     0.918  \n",
       "xg adaboost                                0.025  14591.918     0.900  \n",
       "Random Forest                              0.023  18270.072     0.861  \n",
       "XGBoost, random tree, GB                   0.021  13763.250     0.912  \n",
       "xg Random tree                             0.025  14670.214     0.900  \n",
       "XGBoost, GBoost Random Forest              0.021  13763.250     0.912  \n",
       "LASSO                                      0.097  20087.645     0.755  \n",
       "Ridge alpha 10                             0.055  12898.336     0.892  \n",
       "XGBoost, GBoost Random Forest Ridge        0.010  12891.733     0.930  \n",
       "XGBoost, GBoost Random Forest LASSO        0.017  14171.517     0.909  \n",
       "ENET                                       0.103  18888.261     0.762  \n",
       "XGBoost, GBoost Random Forest ENET         0.017  14041.033     0.911  \n",
       "XGBoost, GBoost Ridge                      0.009  12451.361     0.934  \n",
       "XGBoost, GBoost Ridge Forward              0.013  12531.320     0.931  \n",
       "XGBoost, GBoost Ridge Forward Tree         0.010  12802.761     0.931  \n",
       "XGBoost, GBoost Ridge Forward Lasso        0.022  12929.549     0.917  \n",
       "XGBoost, GBoost, RandomTree                0.021  13763.250     0.912  \n",
       "XGBoost, GBoost Ridge Forward 30 30 20 20  0.010  12553.611     0.932  \n",
       "XGBoost, GBoost Ridge Forward 40 40 10 10  0.012  12742.443     0.929  \n",
       "XGBoost, GBoost Ridge Forward 20 20 30 30  0.018  12563.029     0.927  \n",
       "XGBoost, GBoost Ridge Forward 20 40 20 20  0.009  12521.543     0.934  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResultTable(method,pred)\n",
    "#Using different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "final_train = data.sample(frac=0.6, random_state=1)\n",
    "final_test = data[data.index.isin(final_train.index)==False]\n",
    "final_train.head()\n",
    "y_train = final_train.pop('SalePrice')\n",
    "y_test = final_test.pop('SalePrice')\n",
    "y_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def mae_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(final_train)\n",
    "    mae= -cross_val_score(model, final_train.values, y_train, scoring=\"neg_mean_absolute_error\", cv = kf)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base models\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "LASSO = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "ExtraTrees = ExtraTreesRegressor(criterion='mae',max_depth=None,min_samples_split=2)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "Adaboost = AdaBoostRegressor(loss='linear', learning_rate = 1, n_estimators = 350)\n",
    "\n",
    "model_xgb1 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             nthread = -1)\n",
    "#Kernel Ridge Regression\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=1, coef0=2.5)\n",
    "\n",
    "#ENET\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO SCORE 0.07177067709376508\n",
      "12943.2529984\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(LASSO)\n",
    "print(\"LASSO SCORE {}\".format(score.mean()))\n",
    "LASSO.fit(final_train,y_train)\n",
    "LASSOpred = LASSO.predict(final_test)\n",
    "print(mae(y_test,np.exp(LASSOpred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees SCORE 0.09861611936250789\n",
      "16072.8785699\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(ExtraTrees)\n",
    "print(\"Extra Trees SCORE {}\".format(score.mean()))\n",
    "ExtraTrees.fit(final_train,y_train)\n",
    "pred = ExtraTrees.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost SCORE 0.07951927491985392\n",
      "12968.3053946\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(GBoost)\n",
    "print(\"Gradient Boost SCORE {}\".format(score.mean()))\n",
    "GBoost.fit(final_train,y_train)\n",
    "pred = GBoost.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Boost SCORE 0.10515896352836263\n",
      "18034.624143\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(Adaboost)\n",
    "print(\"Adaboost Boost SCORE {}\".format(score.mean()))\n",
    "Adaboost.fit(final_train,y_train)\n",
    "pred = Adaboost.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost1 SCORE 0.08045839583955512\n",
      "14468.6838849\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(model_xgb1)\n",
    "print(\"XGBoost1 SCORE {}\".format(score.mean()))\n",
    "model_xgb1.fit(final_train,y_train)\n",
    "pred = model_xgb1.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge Regression SCORE 0.07934887428790258\n",
      "13690.8544618\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(KRR)\n",
    "print(\"Kernel Ridge Regression SCORE {}\".format(score.mean()))\n",
    "KRR.fit(final_train,y_train)\n",
    "pred = KRR.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Ridge Regression SCORE 0.07185323395965448\n",
      "12972.2691102\n"
     ]
    }
   ],
   "source": [
    "score = mae_cv(ENet)\n",
    "print(\"Elastic Net Ridge Regression SCORE {}\".format(score.mean()))\n",
    "ENet.fit(final_train,y_train)\n",
    "pred = ENet.predict(final_test)\n",
    "print(mae(y_test,np.exp(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taking average of models\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0749 (0.0046)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (Adaboost, GBoost, model_xgb1, LASSO))\n",
    "score = mae_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0716 (0.0060)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR,ExtraTrees))\n",
    "score = mae_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0720 (0.0049)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR))\n",
    "score = mae_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0690 (0.0041)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (GBoost, LASSO,ENet,KRR))\n",
    "score = mae_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0696 (0.0041)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (GBoost,ENet,KRR))\n",
    "score = mae_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae(y, y_pred):\n",
    "    return (mean_absolute_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "#Python class used for stacking models\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=15)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.values[train_index], y.values[train_index])\n",
    "                y_pred = instance.predict(X.values[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingAveragedModels(base_models=(ExtraTreesRegressor(bootstrap=False, criterion='mae', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators...           presort='auto', random_state=5, subsample=1.0, verbose=0,\n",
       "             warm_start=False)),\n",
       "            meta_model=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='huber', max_depth=4,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=15, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
       "             presort='auto', random_state=5, subsample=1.0, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_folds=5)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ExtraTrees, GBoost),\n",
    "                                                 meta_model = GBoost)\n",
    "\n",
    "stacked_averaged_models.fit(final_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15878.6035184\n"
     ]
    }
   ],
   "source": [
    "stacked_train_pred = stacked_averaged_models.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400.7904897\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_modelsa = StackingAveragedModels(base_models = (ENet, GBoost,KRR),\n",
    "                                                 meta_model = LASSO)\n",
    "\n",
    "stacked_averaged_modelsa.fit(final_train,y_train)\n",
    "stacked_train_pred2 = stacked_averaged_modelsa.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred2)))\n",
    "\n",
    "#Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12402.8824678\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models3 = StackingAveragedModels(base_models = (GBoost, LASSO,ENet,KRR),\n",
    "                                                 meta_model = LASSO)\n",
    "\n",
    "stacked_averaged_models3.fit(final_train,y_train)\n",
    "stacked_train_pred3 = stacked_averaged_models3.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12989.27903\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models4 = StackingAveragedModels(base_models = (GBoost, LASSO,ENet,KRR),\n",
    "                                                 meta_model = model_xgb1)\n",
    "\n",
    "stacked_averaged_models4.fit(final_train,y_train)\n",
    "stacked_train_pred4 = stacked_averaged_models4.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13299.4512689\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models5 = StackingAveragedModels(base_models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR),\n",
    "                                                 meta_model = model_xgb1)\n",
    "\n",
    "stacked_averaged_models5.fit(final_train,y_train)\n",
    "stacked_train_pred5 = stacked_averaged_models5.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12483.4064417\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models5 = StackingAveragedModels(base_models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR),\n",
    "                                                 meta_model = LASSO)\n",
    "\n",
    "stacked_averaged_models5.fit(final_train,y_train)\n",
    "stacked_train_pred5 = stacked_averaged_models5.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12384.3316688\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models5 = StackingAveragedModels(base_models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR,ExtraTrees),\n",
    "                                                 meta_model = LASSO)\n",
    "\n",
    "stacked_averaged_models5.fit(final_train,y_train)\n",
    "stacked_train_pred5 = stacked_averaged_models5.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best meta is Pipeline(memory=None,\n",
      "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=1,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False))]) with MAE of 12483.719962837855\n"
     ]
    }
   ],
   "source": [
    "listofmeta = [Adaboost, GBoost, model_xgb1, LASSO, ENet, KRR,ExtraTrees]\n",
    "best_mae = np.inf\n",
    "bestmeta = ''\n",
    "for x in listofmeta:\n",
    "    \n",
    "    stacked_averaged_models = StackingAveragedModels(base_models = (Adaboost, GBoost, model_xgb1, LASSO,ENet,KRR),\n",
    "                                                 meta_model = x)\n",
    "    stacked_averaged_models.fit(final_train,y_train)\n",
    "    stacked_train_pred = stacked_averaged_models.predict(final_test.values)\n",
    "    curr_mae = mae(y_test,np.exp(stacked_train_pred))\n",
    "    if curr_mae < best_mae:\n",
    "        best_mae = curr_mae\n",
    "        bestmeta = x\n",
    "print(\"Best meta is {} with MAE of {}\".format(bestmeta,best_mae))\n",
    "#Best model to use is LASSO from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12402.7104505\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = ( GBoost,ENet,KRR),\n",
    "                                                 meta_model = LASSO)\n",
    "stacked_averaged_models.fit(final_train,y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(final_test.values)\n",
    "print(mae(y_test,np.exp(stacked_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12320.8213473\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (GBoost, LASSO,ENet,KRR))\n",
    "averaged_models.fit(final_train,y_train)\n",
    "predaverage = averaged_models.predict(final_test)\n",
    "print(mae(y_test,np.exp(predaverage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12258.0086232\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (GBoost,ENet,KRR))\n",
    "averaged_models.fit(final_train,y_train)\n",
    "predaverage = averaged_models.predict(final_test)\n",
    "print(mae(y_test,np.exp(predaverage)))\n",
    "\n",
    "#use this one too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12253.8976872\n"
     ]
    }
   ],
   "source": [
    "predagain = (0.2*stacked_train_pred) + (0.8*predaverage)\n",
    "print(mae(y_test,np.exp(predagain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb1.fit(final_train,y_train)\n",
    "predxg = model_xgb1.predict(final_test)\n",
    "\n",
    "LASSO.fit(final_train,y_train)\n",
    "predlasso = LASSO.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12387.3199553\n"
     ]
    }
   ],
   "source": [
    "predagain2 = (0.2*stacked_train_pred) + (0.4*predaverage) +(0.2*predlasso) + (0.2*predxg)\n",
    "print(mae(y_test,np.exp(predagain2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12292.603685\n"
     ]
    }
   ],
   "source": [
    "predagain2 = (0.2*stacked_train_pred) + (0.6*predaverage) +(0.1*predlasso) + (0.1*predxg)\n",
    "print(mae(y_test,np.exp(predagain2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12472.3567855\n"
     ]
    }
   ],
   "source": [
    "predagain2 = (0.25*stacked_train_pred) + (0.25*predaverage) +(0.25*predlasso) + (0.25*predxg)\n",
    "print(mae(y_test,np.exp(predagain2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train6_1.csv')\n",
    "y_price = data.pop('SalePrice')\n",
    "kaggle = pd.read_csv('Test6_1.csv')\n",
    "y_price = np.log(y_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (GBoost,ENet,KRR))\n",
    "averaged_models.fit(data,y_price)\n",
    "predaverage = averaged_models.predict(kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = ( GBoost,ENet,KRR),\n",
    "                                                 meta_model = LASSO)\n",
    "stacked_averaged_models.fit(data,y_price)\n",
    "stacked_train_pred = stacked_averaged_models.predict(kaggle.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction = np.exp((0.7*predaverage)+ (0.3*stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction = pd.DataFrame({'Id':ind, 'Prediction':finalprediction})\n",
    "#Saving results into CSV file \n",
    "prediction.to_csv(\"Day19_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98089.612287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>155161.131382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>133532.440971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>188068.766965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>144713.767614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>375177.058017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>131185.455299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>281383.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>115099.349226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>127309.433744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>141547.647324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>132370.925356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>182823.693401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>249158.016236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>140014.876702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>111696.331378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>224866.987001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>72784.799591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>180156.265532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>139543.466924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>287600.524282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>194296.861531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>141697.074031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>128551.383979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>134292.275476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>138246.765379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>171376.918582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>117943.275913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>214995.717635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>281946.842839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>235096.585485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1580</td>\n",
       "      <td>262407.748903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1581</td>\n",
       "      <td>147583.813645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1582</td>\n",
       "      <td>198700.975096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1583</td>\n",
       "      <td>123656.752752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>300975.409464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1585</td>\n",
       "      <td>246104.692387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1586</td>\n",
       "      <td>168494.999854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>142346.744919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1588</td>\n",
       "      <td>145072.301649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>118222.259956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1590</td>\n",
       "      <td>95674.631085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1591</td>\n",
       "      <td>125825.492964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1592</td>\n",
       "      <td>158895.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1593</td>\n",
       "      <td>207328.314958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1594</td>\n",
       "      <td>124890.911946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1595</td>\n",
       "      <td>278177.034125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1596</td>\n",
       "      <td>194413.731378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1597</td>\n",
       "      <td>216180.782806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1598</td>\n",
       "      <td>223979.563619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1599</td>\n",
       "      <td>152639.211309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1600</td>\n",
       "      <td>152870.793479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>456198.669237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1602</td>\n",
       "      <td>54260.857883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1603</td>\n",
       "      <td>166906.893534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1604</td>\n",
       "      <td>165708.539045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1605</td>\n",
       "      <td>147177.503348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1606</td>\n",
       "      <td>88508.224718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>194029.387523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1608</td>\n",
       "      <td>212998.134545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Prediction\n",
       "0        1   98089.612287\n",
       "1        2  155161.131382\n",
       "2        3  133532.440971\n",
       "3        4  188068.766965\n",
       "4        5  144713.767614\n",
       "5        6  375177.058017\n",
       "6        7  131185.455299\n",
       "7        8  281383.668333\n",
       "8        9  115099.349226\n",
       "9       10  127309.433744\n",
       "10      11  141547.647324\n",
       "11      12  132370.925356\n",
       "12      13  182823.693401\n",
       "13      14  249158.016236\n",
       "14      15  140014.876702\n",
       "15      16  111696.331378\n",
       "16      17  224866.987001\n",
       "17      18   72784.799591\n",
       "18      19  180156.265532\n",
       "19      20  139543.466924\n",
       "20      21  287600.524282\n",
       "21      22  194296.861531\n",
       "22      23  141697.074031\n",
       "23      24  128551.383979\n",
       "24      25  134292.275476\n",
       "25      26  138246.765379\n",
       "26      27  171376.918582\n",
       "27      28  117943.275913\n",
       "28      29  214995.717635\n",
       "29      30  281946.842839\n",
       "...    ...            ...\n",
       "1578  1579  235096.585485\n",
       "1579  1580  262407.748903\n",
       "1580  1581  147583.813645\n",
       "1581  1582  198700.975096\n",
       "1582  1583  123656.752752\n",
       "1583  1584  300975.409464\n",
       "1584  1585  246104.692387\n",
       "1585  1586  168494.999854\n",
       "1586  1587  142346.744919\n",
       "1587  1588  145072.301649\n",
       "1588  1589  118222.259956\n",
       "1589  1590   95674.631085\n",
       "1590  1591  125825.492964\n",
       "1591  1592  158895.081666\n",
       "1592  1593  207328.314958\n",
       "1593  1594  124890.911946\n",
       "1594  1595  278177.034125\n",
       "1595  1596  194413.731378\n",
       "1596  1597  216180.782806\n",
       "1597  1598  223979.563619\n",
       "1598  1599  152639.211309\n",
       "1599  1600  152870.793479\n",
       "1600  1601  456198.669237\n",
       "1601  1602   54260.857883\n",
       "1602  1603  166906.893534\n",
       "1603  1604  165708.539045\n",
       "1604  1605  147177.503348\n",
       "1605  1606   88508.224718\n",
       "1606  1607  194029.387523\n",
       "1607  1608  212998.134545\n",
       "\n",
       "[1608 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb1.fit(data,y_price)\n",
    "predxg = model_xgb1.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost.fit(data,y_price)\n",
    "predboost = GBoost.predict(kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalprediction2 = np.exp((0.4*predaverage)+ (0.2*stacked_train_pred) + (0.2*predxg)+(0.2*predboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for the indices\n",
    "ind = np.arange(1,1609)\n",
    "headers = ['Id','Prediction']\n",
    "prediction2 = pd.DataFrame({'Id':ind, 'Prediction':finalprediction2})\n",
    "#Saving results into CSV file \n",
    "prediction2.to_csv(\"Day19_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Day 19_5 is when we combine the stack + ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
